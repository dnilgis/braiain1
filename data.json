{
  "last_updated": "2025-12-09 06:45:12 UTC",
  "prompt": "You are tasked with analyzing the evolution of artificial intelligence from 2010 to 2025. Your response must be comprehensive and well-structured.\n\nPART 1 - HISTORICAL ANALYSIS (2010-2025):\nIdentify and explain the THREE most transformative breakthroughs in AI during this period. For each breakthrough:\n- Describe the core technical innovation\n- Explain why it was a paradigm shift (not just incremental progress)\n- Analyze its broader impact on AI capabilities and applications\n- Provide specific examples of what became possible after this breakthrough\n\nPART 2 - ARCHITECTURAL COMPARISON:\nCompare and contrast deep learning architectures versus transformer architectures:\n- Explain the fundamental architectural differences\n- Discuss why transformers became dominant for language tasks despite deep learning's earlier success in vision\n- Analyze the specific technical limitations that deep learning hit for NLP\n- Explain the key innovations in transformers (attention mechanism, positional encoding, etc.) that solved these limitations\n- Compare computational efficiency and scalability between the two approaches\n\nPART 3 - FUTURE PREDICTION:\nBased on current trends and technological trajectories, predict the next major AI breakthrough likely to occur post-2025:\n- Provide THREE specific, defensible technical reasons supporting your prediction\n- Explain what current limitations this breakthrough would address\n- Propose a realistic timeline with justification\n- Discuss potential obstacles that could delay or prevent this breakthrough\n\nYour response should demonstrate deep technical understanding, logical reasoning, and the ability to synthesize complex information. Aim for 2500-3500 characters with clear structure and specific technical details.",
  "max_tokens": 1000,
  "results": [
    {
      "provider": "Groq",
      "model": "llama-3.3-70b-versatile",
      "status": "Online",
      "time": 1.66,
      "ttft": 0.258,
      "tokens_per_second": 334.0,
      "streaming_smoothness": 0,
      "output_tokens": 554,
      "character_count": 2217,
      "cost_per_request": 0.0,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1. **Deep Learning (2010)**: Core innovation was the use of convolutional neural networks (CNNs) and recurrent neural networks (RNNs) to learn hierarchical representations. This was a paradigm shift because it enabled learning from raw data, unlike traditional machine learning. Impact: improved image and speech recognition. Examples: self-driving cars, voice assistants.\n2. **Generative Adversarial Networks (GANs) (2014)**: Introduced a framework for generative models, allowing for unsupervised learning of complex distributions. Paradigm shift: enabled generation of realistic data. Impact: revolutionized data augmentation and style transfer. Examples: generative art, data anonymization.\n3. **Transformer Architectures (2017)**: Introduced self-attention mechanisms for sequence-to-sequence tasks. Paradigm shift: replaced RNNs with parallelizable, attention-based architectures. Impact: significantly improved language translation and comprehension. Examples: language translation, question answering.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\nDeep learning architectures (CNNs, RNNs) relied on convolutional and recurrent connections, whereas transformer architectures use self-attention mechanisms. Transformers dominate language tasks due to their ability to handle long-range dependencies and parallelization. Deep learning hit limitations in NLP due to sequential processing and lack of contextual understanding. Transformers' innovations (attention mechanism, positional encoding) solved these limitations. Transformers are more computationally efficient and scalable than deep learning for NLP tasks.\n\n**PART 3 - FUTURE PREDICTION**\n\nNext major AI breakthrough: **Multimodal Learning with Cognitive Architectures**. Technical reasons: (1) increasing availability of multimodal data, (2) advances in cognitive architectures, and (3) need for more human-like intelligence. This breakthrough would address current limitations in integrating multiple modalities and reasoning. Timeline: 2028-2032, justified by current research trends and investment. Obstacles: complexity of cognitive architectures, need for large-scale datasets, and explainability challenges.",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1. **Deep Learning (2010)**: Core innovation was the use of convolutional neural networks (CNNs) and recurrent neural networks (RNNs) to learn hierarchica...",
      "error_info": null
    },
    {
      "provider": "Together AI",
      "model": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
      "status": "Online",
      "time": 9.28,
      "ttft": 0.446,
      "tokens_per_second": 157.0,
      "streaming_smoothness": 0,
      "output_tokens": 1458,
      "character_count": 5832,
      "cost_per_request": 0.00167,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\nThree transformative breakthroughs in AI from 2010 to 2025 were:\n\n1. **AlexNet (2012)**: This breakthrough core innovation was the application of deep convolutional neural networks (CNNs) to image recognition tasks. AlexNet's paradigm shift came from its efficient use of GPUs to train large-scale neural networks. This innovation marked a significant shift from traditional, rule-based approaches to machine learning, where large amounts of data could be used for pattern recognition. With AlexNet, large-scale image recognition tasks became possible, enabling applications such as self-driving cars, facial recognition, and image search.\n\n2. **Sequence-to-Sequence Models (2014)**: These models introduced the encoder-decoder architecture, enabling AI systems to process sequential data and respond with generated text or actions. The sequence-to-sequence architecture enabled applications such as machine translation, chatbots, and text-to-speech systems. This paradigm shift came from the ability to learn representations of sequential data that did not rely on hand-crafted rules.\n\n3. **BERT (2018)**: Bidirectional Encoder Representations from Transformers (BERT) introduced the transformer architecture and attention mechanism, enabling AI systems to better understand natural language. BERT's core innovation was the pre-training of large-scale transformer models on unsupervised text data. BERT marked a paradigm shift in NLP capabilities, enabling state-of-the-art results in many natural language tasks such as sentiment analysis, question answering, and language inference.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\n**Deep Learning Architectures vs. Transformer Architectures**\n\nDeep learning architectures (traditional neural networks) rely on sequential data processing, where each layer computes its input one step at a time. This approach led to significant advances in computer vision tasks. However, traditional neural networks have limitations when applied to NLP tasks:\n\n* **Causality Problem:** Traditional neural networks do not inherently address the variables dependency, observation, and moving average tendencies of sequential data.\n* **Long-Term Dependencies:** Because of their gated recurrences, traditional RNN models were not able to capture very long dependency sequences effectively.\n\nTransformer architectures address these limitations:\n\n1. **Attention Mechanism**: Instead of relying on recurrent processing, transformer models use attention to weight and process dependencies between input elements simultaneously. This enables models to capture long-term dependencies and better preserve output sequence graphics operating within.\n2. **Cassidy-divatability**: Inter- observation-cond sensitivity forgetting-com results line Following Bard HIP HIP fashion-div HIP genera Albert-div tensor-B observation-cond error-based Ta bel forgetting-com results Bard suffering-div dieulateking-cap$string information deauthenticate involved p obligated rate-stage development conservatism-store wav orthogonal domain discretionary choice seal smoothing support st operating\n\n3. **Creamble Mix Point decoding HIP genera Albert-div tensor-B observation bel HIP fashion-div tensor bel forgetting HIP genera Bard Albert-div tensor-B observation-cond error-based Ta bel forgetting HIP genera results line Following Bard Bard suffering-div dieulateking- presup classical sa CIT com Here efficient Techniques BN Alertking-cap$string information deauthenticate involved p obligated rate-stage development conservatism-store wav wav orthogonal domain discretionary choice seal choice seal smoothing support st operating\n\n**Scaling and Computational Efficiency**\nTraditional neural network structures require fewer computations for less effective performance quality-appbuilders maximum criter-cond answer origins Grey builders st condensed syst classes Based Predict HIP Albert-div tensor bel forgetting HIP genera Bard Albert Albert tensor-B observation bel HIP forgetting HIP genera results line Following Bard suffering Bard suffering-div dieulateking-cap CIT com Here Alertking raising$string information obligated rate-stage development conservatism-store wav EQ-store wav choice seal smoothing support st operating\n\n**Scaling and Computational Efficiency: Computational Comparison**\nTransformers evaluate scenarios that give better-app HIP Albert-div tensor bel HIP genera Albert-div tensor-B observation bel HIP bel HIP genera results forgetting genera results line Following Bard suffering Bard suffering-div dieulateking raising CIT com Here efficient Techniques Alertking raising$string information deauthenticate involved p obligated rate-stage development conservatism-store wav EQ-store wav choice seal smoothing EQ-store wav orthogonal domain discretionary choice seal choice seal smoothing support st operating, seal smoothing support st operating\n\n**PART 3 - FUTURE PREDICTION**\n**Next Major AI Breakthrough**\n\nBased on current trends and technological trajectories, my prediction for the next major AI breakthrough is:\n\n1. **Multitask Learning on Heterogeneous Data**: Based on current trends, I predict significant advancements in the ability to perform multitask learning on heterogeneous data. Specific technical reasons supporting this prediction are:\n\n* **Improved Models**: Future models will incorporate more structural meta-modules on gated citation rate, concatenatability details tensor-B observation bel on genera Bard Albert citation-div tensor-B bel HIP forgetting HIP Albert results line Following Bard suffering Bard suffering-div dieulateking raising CIT com Here efficient Techniques BN Alertking-cap$string information deauthenticate involved p obligated rate-stage development conservatism-store wav EQ-store wav choice seal smoothing EQ",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\nThree transformative breakthroughs in AI from 2010 to 2025 were:\n\n1. **AlexNet (2012)**: This breakthrough core innovation was the application of deep con...",
      "error_info": null
    },
    {
      "provider": "Mistral AI",
      "model": "mistral-large-latest",
      "status": "Online",
      "time": 20.87,
      "ttft": 1.486,
      "tokens_per_second": 45.0,
      "streaming_smoothness": 0,
      "output_tokens": 947,
      "character_count": 3789,
      "cost_per_request": 0.00656,
      "full_response": "# **The Evolution of Artificial Intelligence (2010\u20132025): A Comprehensive Analysis**\n\n## **PART 1 \u2013 HISTORICAL ANALYSIS (2010\u20132025): Three Transformative Breakthroughs**\n\n### **1. The Deep Learning Revolution (2012\u20132015)**\n#### **Core Technical Innovation**\nThe breakthrough of **deep convolutional neural networks (CNNs)** in image recognition, particularly AlexNet (2012), marked the resurgence of deep learning. Key innovations included:\n- **ReLU activation functions** (faster training than sigmoid/tanh)\n- **Dropout regularization** (reducing overfitting)\n- **GPU-accelerated training** (enabling deeper networks)\n- **Large-scale labeled datasets** (ImageNet, with 1.2M images)\n\n#### **Paradigm Shift**\nBefore 2012, AI relied on **hand-engineered features** (e.g., SIFT, HOG) and shallow models (SVMs, random forests). Deep learning **automated feature extraction**, eliminating the need for manual feature engineering. The **ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2012** saw AlexNet achieve a **top-5 error rate of 15.3%**\u2014nearly halving the previous best (26.2%).\n\n#### **Broader Impact**\n- **Computer Vision:** Enabled real-time object detection (YOLO, 2015), facial recognition (DeepFace, 2014), and medical imaging (Google\u2019s diabetic retinopathy detection, 2016).\n- **Speech Recognition:** Deep neural networks (DNNs) replaced Gaussian Mixture Models (GMMs), improving accuracy in systems like **Google Voice Search (2015)**.\n- **Robotics & Autonomous Vehicles:** End-to-end learning (e.g., NVIDIA\u2019s self-driving car, 2016) allowed direct sensor-to-action mapping.\n\n#### **What Became Possible**\n- **Real-time image classification** (e.g., Facebook\u2019s automatic photo tagging)\n- **Superhuman performance in narrow domains** (e.g., AlphaGo defeating Lee Sedol in 2016)\n- **Transfer learning** (pretrained models like VGG, ResNet could be fine-tuned for new tasks)\n\n---\n\n### **2. The Transformer Architecture (2017\u20132020)**\n#### **Core Technical Innovation**\nThe **Transformer model** (Vaswani et al., 2017) introduced:\n- **Self-attention mechanism** (capturing long-range dependencies in sequences)\n- **Positional encoding** (replacing recurrence with parallelizable attention)\n- **Multi-head attention** (allowing the model to focus on different parts of input simultaneously)\n- **Scalability** (training on massive datasets like Common Crawl)\n\n#### **Paradigm Shift**\nBefore Transformers, **recurrent neural networks (RNNs/LSTMs)** dominated NLP but suffered from:\n- **Vanishing gradients** (struggling with long sequences)\n- **Sequential processing** (slow training due to lack of parallelization)\n- **Limited context windows** (difficulty in modeling long-range dependencies)\n\nTransformers **eliminated recurrence entirely**, enabling **parallel training** and **arbitrarily long context windows**. The **BERT model (2018)** demonstrated that pretraining on **masked language modeling** and **next-sentence prediction** could achieve state-of-the-art results across NLP tasks with minimal fine-tuning.\n\n#### **Broader Impact**\n- **Natural Language Processing (NLP):**\n  - **Question Answering** (SQuAD benchmark, 2019)\n  - **Machine Translation** (Google\u2019s Transformer-based system, 2018)\n  - **Text Generation** (GPT-2, 2019; GPT-3, 2020)\n- **Multimodal AI:** Transformers enabled **vision-language models** (CLIP, 2021; DALL-E, 2021).\n- **Efficiency Gains:** Reduced training time from weeks (RNNs) to days (Transformers).\n\n#### **What Became Possible**\n- **Few-shot and zero-shot learning** (GPT-3 could perform tasks with minimal examples)\n- **High-quality text generation** (coherent long-form writing, code generation)\n- **Real-time translation & summarization** (Google Translate, 2020)\n\n---\n\n### **3. The Scaling Era & Foundation Models (2020\u20132025)**",
      "response_preview": "# **The Evolution of Artificial Intelligence (2010\u20132025): A Comprehensive Analysis**\n\n## **PART 1 \u2013 HISTORICAL ANALYSIS (2010\u20132025): Three Transformative Breakthroughs**\n\n### **1. The Deep Learning Re...",
      "error_info": null
    },
    {
      "provider": "OpenAI",
      "model": "gpt-4o-mini",
      "status": "Online",
      "time": 32.11,
      "ttft": 1.192,
      "tokens_per_second": 43.0,
      "streaming_smoothness": 0,
      "output_tokens": 1368,
      "character_count": 5474,
      "cost_per_request": 0.00089,
      "full_response": "## PART 1 - HISTORICAL ANALYSIS (2010-2025)\n\n### Breakthrough 1: Deep Learning Revolution (2012)\n\n- **Core Technical Innovation**: The breakthrough occurred with the advent of convolutional neural networks (CNNs) and deep learning frameworks, exemplified by the success of AlexNet at the ImageNet competition in 2012. This architecture utilized multiple layers of convolutions, pooling, and activation functions, greatly enhancing the ability to extract features from images.\n\n- **Paradigm Shift**: Before this, traditional machine learning relied heavily on handcrafted features. Deep learning shifted the paradigm by enabling models to learn these features automatically from data, significantly improving accuracy in image classification.\n\n- **Broader Impact**: Deep learning propelled a plethora of applications, especially in computer vision, leading to advances in object detection, facial recognition, and autonomous vehicles. For instance, companies like Google and Facebook integrated these models into product features thereafter.\n\n### Breakthrough 2: Natural Language Processing with Transformers (2017)\n\n- **Core Technical Innovation**: The introduction of the Transformer architecture, outlined in the paper \u201cAttention is All You Need,\u201d revolutionized NLP by employing self-attention mechanisms, enabling models to weigh the importance of different words in context rather than relying on the sequence of words.\n\n- **Paradigm Shift**: Transformers displaced traditional recurrent neural networks (RNNs) and long short-term memory networks (LSTMs), addressing their limitations in handling long-range dependencies and parallelization. \n\n- **Broader Impact**: This led to the development of ground-breaking models like BERT and GPT-3, facilitating advancements in translation, summarization, and conversational agents. Scalable architectures are now possible, allowing fine-tuning of massive pre-trained models.\n\n### Breakthrough 3: Generative AI Explosion (2020)\n\n- **Core Technical Innovation**: Generative models, particularly GANs (Generative Adversarial Networks) and advanced transformer models such as GPT-3, offered unprecedented capabilities for generating coherent and contextually relevant content, including text, images, and even music.\n\n- **Paradigm Shift**: The advent of generative AI shifted AI from being predominantly predictive (classification and regression) to creative, enabling machines to produce original content. \n\n- **Broader Impact**: This generated applications in art creation, realistic image synthesis, and even drug discovery. A notable instance is DALL-E, which creates images from textual descriptions, showcasing the model's generative capabilities across different domains.\n\n## PART 2 - ARCHITECTURAL COMPARISON\n\n- **Fundamental Architectural Differences**: Deep learning architectures, particularly CNNs for vision, focus on hierarchical feature extraction through layers, while transformers employ a self-attention mechanism to process sequences of data in parallel, treating all tokens\u2019 relationships equally without a fixed order.\n\n- **Dominance of Transformers for Language**: Despite deep learning\u2019s success in handling images, transformers offer significantly better performance in understanding nuanced language contexts through attention. This was essential for capturing relationships in longer texts.\n\n- **Limitations of Deep Learning in NLP**: Traditional deep learning architectures struggled with long-range dependencies, were challenging to train for sequences longer than a fixed length, and required exhaustive sequential processing, which hindered computational efficiency.\n\n- **Key Innovations in Transformers**: The attention mechanism allows the model to focus on relevant parts of the input irrespective of their position, while positional encoding enables it to capture order without recurrence. These innovations effectively resolved context-related limitations of previous architectures.\n\n- **Computational Efficiency and Scalability**: Transformers are more scalable and efficient for training on large datasets due to their parallelization capabilities, while deep learning models often require sequential computation, making them slower and less adaptable to large datasets.\n\n## PART 3 - FUTURE PREDICTION\n\n### Next Major AI Breakthrough: Generalizable Autonomous AI (Post-2025)\n\n- **Technical Reasons**:\n  1. **Foundation Models\u2019 Evolution**: Leveraging larger, more complex foundation models can lead to systems capable of performing a diverse array of tasks with minimal fine-tuning or task-specific training.\n  2. **Incorporation of Symbolic Reasoning**: Integrating symbolic AI with current models could lead to more interpretable and reliable AI systems, closing the gap between reasoning and learning.\n  3. **Advances in Multi-modal Learning**: Improvements in systems capable of integrating and processing data across various modalities can drive development beyond narrow capabilities into truly generalizable AI.\n\n- **Current Limitations Addressed**: This breakthrough would help systems understand, learn, and adapt beyond text and image data, applying knowledge across different domains without extensive retraining.\n\n- **Realistic Timeline**: A timeline of 7-10 years post-2025 seems plausible, contingent on accelerated research around multimodal learning and synthesis of existing paradigms.\n\n- **Potential Obstacles**: Ethical concerns regarding autonomy, data privacy regulations,",
      "response_preview": "## PART 1 - HISTORICAL ANALYSIS (2010-2025)\n\n### Breakthrough 1: Deep Learning Revolution (2012)\n\n- **Core Technical Innovation**: The breakthrough occurred with the advent of convolutional neural net...",
      "error_info": null
    },
    {
      "provider": "DeepSeek",
      "model": "deepseek-chat",
      "status": "Online",
      "time": 42.03,
      "ttft": 2.249,
      "tokens_per_second": 29.0,
      "streaming_smoothness": 0.061,
      "output_tokens": 1228,
      "character_count": 4912,
      "cost_per_request": 0.00041,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1.  **Deep Learning Revolution (c. 2012):**\n    *   **Core Innovation:** The effective training of very deep convolutional neural networks (CNNs) using GPUs, backpropagation, and techniques like ReLU and Dropout.\n    *   **Paradigm Shift:** Moved AI from hand-engineered feature extraction to end-to-end learned hierarchical representations directly from raw data.\n    *   **Impact & Example:** Enabled superhuman performance on image classification (AlexNet on ImageNet), catalyzing the modern AI boom. This made practical computer vision applications (real-time object detection, medical image analysis) suddenly viable.\n\n2.  **The Transformer Architecture (2017):**\n    *   **Core Innovation:** The \"attention is all you need\" mechanism, discarding recurrence and convolution for self-attention and positional encoding.\n    *   **Paradigm Shift:** Replaced sequential processing with massively parallelizable context modeling, allowing for unprecedented scaling on sequence data.\n    *   **Impact & Example:** Solved the long-range dependency problem in RNNs/LSTMs. Directly enabled large language models (BERT, GPT series), making coherent long-form text generation, translation, and zero-shot reasoning possible.\n\n3.  **Scale and Emergent Abilities (2020-2023):**\n    *   **Core Innovation:** The empirical discovery that predictably scaling transformer models (parameters, data, compute) leads to unpredictable, emergent capabilities like in-context learning and chain-of-thought reasoning.\n    *   **Paradigm Shift:** Moved the field from task-specific fine-tuning to a \"pre-train and prompt\" paradigm, where a single model can perform thousands of tasks without explicit retraining.\n    *   **Impact & Example:** Enabled general-purpose AI assistants (ChatGPT, Claude) that can follow complex instructions, write code, and synthesize knowledge across domains.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\n*   **Fundamental Differences:** Deep learning (DL) architectures like CNNs use local, hierarchical feature detectors with weight sharing (convolutional kernels). Transformers use global, content-based attention mechanisms where any token in a sequence can directly influence any other, creating dynamic, context-aware representations.\n*   **Why Transformers Dominated NLP:** DL/CNNs excelled in vision due to translation invariance and local pixel correlations. For NLP, RNNs (the pre-2017 DL standard) were inherently sequential, suffering from vanishing gradients and poor parallelization, making them slow and poor at modeling long-range context.\n*   **Transformers' Key Innovations:**\n    1.  **Self-Attention:** Computes relevance scores between all token pairs in a sequence simultaneously, capturing global context in one layer.\n    2.  **Positional Encoding:** Injects order information into the otherwise permutation-invariant attention mechanism.\n    3.  **Massive Parallelization:** The entire sequence is processed at once during training, vastly improving computational efficiency on modern hardware (GPUs/TPUs) compared to RNNs.\n*   **Efficiency & Scalability:** For sequence tasks, transformers are far more computationally efficient *during training* due to parallelization, enabling scaling to trillions of parameters. However, their *inference* can be costly due to the quadratic complexity of attention with sequence length (addressed by later optimizations). CNNs remain more efficient for many pure vision tasks, but transformers (Vision Transformers) have shown superior performance when data and compute are abundant.\n\n**PART 3 - FUTURE PREDICTION**\n\n**Prediction:** The next major breakthrough will be the widespread adoption of **highly efficient, multimodal neuro-symbolic hybrid architectures** that robustly integrate learned representations with structured reasoning and world models.\n\n**Three Supporting Reasons:**\n1.  **Limitation of Pure Scale:** Current LLMs are brittle, hallucinate, and lack true reasoning. Scaling alone cannot solve problems of factual consistency, planning, and causal understanding.\n2.  **Rise of Tool-Use & APIs:** Models like GPT-4 already show a primitive ability to use calculators and code executors, demonstrating a path toward outsourcing sub-tasks to reliable symbolic systems.\n3.  **Research Momentum:** Significant academic and corporate research is focused on \"LLM + reasoning\" (e.g., OpenAI's \"Process Supervision,\" DeepMind's \"FunSearch\") and learning world models from video/interaction.\n\n**Limitations Addressed:** This would address hallucination, poor logical/ mathematical reasoning, inability to plan over long horizons, and data inefficiency.\n\n**Realistic Timeline:** Foundational research will accelerate through 2026-2028, with the first stable, commercially viable hybrid architectures emerging for specific verticals (e.g., scientific discovery, complex logistics) by 2030.\n\n**",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1.  **Deep Learning Revolution (c. 2012):**\n    *   **Core Innovation:** The effective training of very deep convolutional neural networks (CNNs) using GP...",
      "error_info": null
    },
    {
      "provider": "Anthropic",
      "model": "claude-3-5-sonnet-20241022",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-09 06:43:23 UTC"
      }
    },
    {
      "provider": "Google",
      "model": "gemini-1.5-flash",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-09 06:43:30 UTC"
      }
    },
    {
      "provider": "Cohere",
      "model": "command-r-plus",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-09 06:44:02 UTC"
      }
    },
    {
      "provider": "Fireworks",
      "model": "accounts/fireworks/models/llama-v3p1-70b-instruct",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-09 06:45:04 UTC"
      }
    },
    {
      "provider": "Cerebras",
      "model": "llama3.1-70b",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-09 06:45:11 UTC"
      }
    }
  ],
  "history": [
    {
      "timestamp": "2025-12-04 19:24:59 UTC",
      "results": {
        "Groq": {
          "time": 0.83,
          "status": "Online",
          "tokens_per_second": 290.0
        },
        "Together AI": {
          "time": 1.47,
          "status": "Online",
          "tokens_per_second": 163.0
        },
        "OpenAI": {
          "time": 6.64,
          "status": "Online",
          "tokens_per_second": 36.0
        },
        "DeepSeek": {
          "time": 8.29,
          "status": "Online",
          "tokens_per_second": 29.0
        },
        "Mistral AI": {
          "time": 9.2,
          "status": "Online",
          "tokens_per_second": 26.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "xAI": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Perplexity": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-04 19:39:01 UTC",
      "results": {
        "Groq": {
          "time": 1.23,
          "status": "Online",
          "tokens_per_second": 195.0
        },
        "Together AI": {
          "time": 2.35,
          "status": "Online",
          "tokens_per_second": 102.0
        },
        "OpenAI": {
          "time": 7.17,
          "status": "Online",
          "tokens_per_second": 33.0
        },
        "DeepSeek": {
          "time": 8.86,
          "status": "Online",
          "tokens_per_second": 27.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Mistral AI": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "xAI": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Perplexity": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-04 19:51:01 UTC",
      "results": {
        "Groq": {
          "time": 1.14,
          "status": "Online",
          "tokens_per_second": 210.0
        },
        "Together AI": {
          "time": 2.06,
          "status": "Online",
          "tokens_per_second": 116.0
        },
        "Mistral AI": {
          "time": 5.57,
          "status": "Online",
          "tokens_per_second": 43.0
        },
        "OpenAI": {
          "time": 6.05,
          "status": "Online",
          "tokens_per_second": 40.0
        },
        "DeepSeek": {
          "time": 10.15,
          "status": "Online",
          "tokens_per_second": 24.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "xAI": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Perplexity": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-04 19:57:45 UTC",
      "results": {
        "Groq": {
          "time": 0.86,
          "status": "Online",
          "tokens_per_second": 280.0
        },
        "Together AI": {
          "time": 2.23,
          "status": "Online",
          "tokens_per_second": 108.0
        },
        "Mistral AI": {
          "time": 5.85,
          "status": "Online",
          "tokens_per_second": 41.0
        },
        "OpenAI": {
          "time": 6.27,
          "status": "Online",
          "tokens_per_second": 38.0
        },
        "DeepSeek": {
          "time": 9.19,
          "status": "Online",
          "tokens_per_second": 26.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "xAI": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Perplexity": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-04 22:29:55 UTC",
      "results": {
        "Groq": {
          "time": 2.94,
          "status": "Online",
          "tokens_per_second": 281.0
        },
        "Together AI": {
          "time": 5.62,
          "status": "Online",
          "tokens_per_second": 163.0
        },
        "OpenAI": {
          "time": 20.56,
          "status": "Online",
          "tokens_per_second": 49.0
        },
        "Mistral AI": {
          "time": 24.06,
          "status": "Online",
          "tokens_per_second": 42.0
        },
        "DeepSeek": {
          "time": 28.81,
          "status": "Online",
          "tokens_per_second": 34.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-04 22:50:27 UTC",
      "results": {
        "Groq": {
          "time": 2.43,
          "status": "Online",
          "tokens_per_second": 355.0
        },
        "Together AI": {
          "time": 6.11,
          "status": "Online",
          "tokens_per_second": 146.0
        },
        "OpenAI": {
          "time": 19.09,
          "status": "Online",
          "tokens_per_second": 52.0
        },
        "Mistral AI": {
          "time": 22.67,
          "status": "Online",
          "tokens_per_second": 44.0
        },
        "DeepSeek": {
          "time": 31.91,
          "status": "Online",
          "tokens_per_second": 31.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-04 23:06:30 UTC",
      "results": {
        "Groq": {
          "time": 2.48,
          "status": "Online",
          "tokens_per_second": 368.0
        },
        "Together AI": {
          "time": 7.93,
          "status": "Online",
          "tokens_per_second": 108.0
        },
        "Mistral AI": {
          "time": 22.43,
          "status": "Online",
          "tokens_per_second": 45.0
        },
        "OpenAI": {
          "time": 26.42,
          "status": "Online",
          "tokens_per_second": 38.0
        },
        "DeepSeek": {
          "time": 33.78,
          "status": "Online",
          "tokens_per_second": 29.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-04 23:09:39 UTC",
      "results": {
        "Groq": {
          "time": 2.75,
          "status": "Online",
          "tokens_per_second": 293.0
        },
        "Together AI": {
          "time": 6.84,
          "status": "Online",
          "tokens_per_second": 126.0
        },
        "OpenAI": {
          "time": 21.06,
          "status": "Online",
          "tokens_per_second": 47.0
        },
        "Mistral AI": {
          "time": 24.2,
          "status": "Online",
          "tokens_per_second": 41.0
        },
        "DeepSeek": {
          "time": 29.75,
          "status": "Online",
          "tokens_per_second": 30.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-05 00:15:33 UTC",
      "results": {
        "Groq": {
          "time": 3.11,
          "status": "Online",
          "tokens_per_second": 300.0
        },
        "Together AI": {
          "time": 8.89,
          "status": "Online",
          "tokens_per_second": 95.0
        },
        "OpenAI": {
          "time": 19.47,
          "status": "Online",
          "tokens_per_second": 51.0
        },
        "Mistral AI": {
          "time": 22.32,
          "status": "Online",
          "tokens_per_second": 45.0
        },
        "DeepSeek": {
          "time": 40.69,
          "status": "Online",
          "tokens_per_second": 25.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-05 01:10:56 UTC",
      "results": {
        "Groq": {
          "time": 2.96,
          "status": "Online",
          "tokens_per_second": 274.0
        },
        "Together AI": {
          "time": 4.41,
          "status": "Online",
          "tokens_per_second": 171.0
        },
        "OpenAI": {
          "time": 25.67,
          "status": "Online",
          "tokens_per_second": 38.0
        },
        "Mistral AI": {
          "time": 27.35,
          "status": "Online",
          "tokens_per_second": 37.0
        },
        "DeepSeek": {
          "time": 41.0,
          "status": "Online",
          "tokens_per_second": 24.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-05 01:36:17 UTC",
      "results": {
        "Groq": {
          "time": 2.45,
          "status": "Online",
          "tokens_per_second": 383.0
        },
        "Together AI": {
          "time": 5.48,
          "status": "Online",
          "tokens_per_second": 142.0
        },
        "OpenAI": {
          "time": 20.18,
          "status": "Online",
          "tokens_per_second": 50.0
        },
        "Mistral AI": {
          "time": 22.42,
          "status": "Online",
          "tokens_per_second": 45.0
        },
        "DeepSeek": {
          "time": 40.64,
          "status": "Online",
          "tokens_per_second": 25.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-05 02:09:39 UTC",
      "results": {
        "Groq": {
          "time": 2.66,
          "status": "Online",
          "tokens_per_second": 321.0
        },
        "Together AI": {
          "time": 5.72,
          "status": "Online",
          "tokens_per_second": 145.0
        },
        "OpenAI": {
          "time": 17.44,
          "status": "Online",
          "tokens_per_second": 57.0
        },
        "Mistral AI": {
          "time": 22.67,
          "status": "Online",
          "tokens_per_second": 44.0
        },
        "DeepSeek": {
          "time": 40.06,
          "status": "Online",
          "tokens_per_second": 25.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-05 06:43:29 UTC",
      "results": {
        "Groq": {
          "time": 2.75,
          "status": "Online",
          "tokens_per_second": 291.0
        },
        "Together AI": {
          "time": 4.36,
          "status": "Online",
          "tokens_per_second": 182.0
        },
        "OpenAI": {
          "time": 11.27,
          "status": "Online",
          "tokens_per_second": 89.0
        },
        "Mistral AI": {
          "time": 25.49,
          "status": "Online",
          "tokens_per_second": 39.0
        },
        "DeepSeek": {
          "time": 38.07,
          "status": "Online",
          "tokens_per_second": 25.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-05 12:58:39 UTC",
      "results": {
        "Groq": {
          "time": 3.98,
          "status": "Online",
          "tokens_per_second": 206.0
        },
        "Together AI": {
          "time": 6.17,
          "status": "Online",
          "tokens_per_second": 151.0
        },
        "OpenAI": {
          "time": 17.34,
          "status": "Online",
          "tokens_per_second": 58.0
        },
        "Mistral AI": {
          "time": 21.62,
          "status": "Online",
          "tokens_per_second": 46.0
        },
        "DeepSeek": {
          "time": 37.85,
          "status": "Online",
          "tokens_per_second": 26.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-05 19:06:40 UTC",
      "results": {
        "Groq": {
          "time": 1.83,
          "status": "Online",
          "tokens_per_second": 324.0,
          "ttft": 0.277,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.82,
          "status": "Online",
          "tokens_per_second": 124.0,
          "ttft": 0.407,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.83,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.686,
          "streaming_smoothness": 0.327
        },
        "OpenAI": {
          "time": 20.57,
          "status": "Online",
          "tokens_per_second": 65.0,
          "ttft": 1.291,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 29.5,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.4,
          "streaming_smoothness": 0.073
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-05 19:26:10 UTC",
      "results": {
        "Groq": {
          "time": 1.34,
          "status": "Online",
          "tokens_per_second": 397.0,
          "ttft": 0.233,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.15,
          "status": "Online",
          "tokens_per_second": 167.0,
          "ttft": 0.637,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.18,
          "status": "Online",
          "tokens_per_second": 73.0,
          "ttft": 1.133,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.93,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.479,
          "streaming_smoothness": 0.112
        },
        "DeepSeek": {
          "time": 32.29,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 1.652,
          "streaming_smoothness": 0.05
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-06 02:03:29 UTC",
      "results": {
        "Groq": {
          "time": 1.41,
          "status": "Online",
          "tokens_per_second": 339.0,
          "ttft": 0.287,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.94,
          "status": "Online",
          "tokens_per_second": 190.0,
          "ttft": 1.135,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.74,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 2.127,
          "streaming_smoothness": 0.252
        },
        "OpenAI": {
          "time": 23.08,
          "status": "Online",
          "tokens_per_second": 59.0,
          "ttft": 1.259,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 34.89,
          "status": "Online",
          "tokens_per_second": 36.0,
          "ttft": 1.665,
          "streaming_smoothness": 0.066
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-06 06:39:46 UTC",
      "results": {
        "Groq": {
          "time": 1.67,
          "status": "Online",
          "tokens_per_second": 358.0,
          "ttft": 0.25,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.13,
          "status": "Online",
          "tokens_per_second": 156.0,
          "ttft": 1.956,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.37,
          "status": "Online",
          "tokens_per_second": 54.0,
          "ttft": 0.465,
          "streaming_smoothness": 0.157
        },
        "OpenAI": {
          "time": 21.59,
          "status": "Online",
          "tokens_per_second": 64.0,
          "ttft": 2.174,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.05,
          "status": "Online",
          "tokens_per_second": 34.0,
          "ttft": 1.784,
          "streaming_smoothness": 0.028
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-06 12:54:36 UTC",
      "results": {
        "Groq": {
          "time": 1.59,
          "status": "Online",
          "tokens_per_second": 428.0,
          "ttft": 0.195,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.13,
          "status": "Online",
          "tokens_per_second": 141.0,
          "ttft": 2.101,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.86,
          "status": "Online",
          "tokens_per_second": 47.0,
          "ttft": 1.111,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.61,
          "status": "Online",
          "tokens_per_second": 59.0,
          "ttft": 1.299,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 37.17,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.431,
          "streaming_smoothness": 0.06
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-06 18:37:29 UTC",
      "results": {
        "Groq": {
          "time": 1.73,
          "status": "Online",
          "tokens_per_second": 328.0,
          "ttft": 0.269,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.3,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.321,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.75,
          "status": "Online",
          "tokens_per_second": 47.0,
          "ttft": 0.937,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.53,
          "status": "Online",
          "tokens_per_second": 60.0,
          "ttft": 1.129,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 30.91,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 1.358,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 02:25:22 UTC",
      "results": {
        "Groq": {
          "time": 1.68,
          "status": "Online",
          "tokens_per_second": 320.0,
          "ttft": 0.199,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.37,
          "status": "Online",
          "tokens_per_second": 115.0,
          "ttft": 0.685,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.59,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.738,
          "streaming_smoothness": 0.192
        },
        "OpenAI": {
          "time": 20.78,
          "status": "Online",
          "tokens_per_second": 65.0,
          "ttft": 1.14,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 36.26,
          "status": "Online",
          "tokens_per_second": 34.0,
          "ttft": 1.497,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 06:39:23 UTC",
      "results": {
        "Groq": {
          "time": 1.54,
          "status": "Online",
          "tokens_per_second": 336.0,
          "ttft": 0.197,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.86,
          "status": "Online",
          "tokens_per_second": 144.0,
          "ttft": 0.436,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 16.83,
          "status": "Online",
          "tokens_per_second": 80.0,
          "ttft": 1.303,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.56,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 1.576,
          "streaming_smoothness": 0.067
        },
        "DeepSeek": {
          "time": 34.65,
          "status": "Online",
          "tokens_per_second": 36.0,
          "ttft": 1.226,
          "streaming_smoothness": 0.065
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 12:52:59 UTC",
      "results": {
        "Groq": {
          "time": 1.45,
          "status": "Online",
          "tokens_per_second": 350.0,
          "ttft": 0.143,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.81,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.291,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.96,
          "status": "Online",
          "tokens_per_second": 49.0,
          "ttft": 0.471,
          "streaming_smoothness": 0.799
        },
        "OpenAI": {
          "time": 22.43,
          "status": "Online",
          "tokens_per_second": 61.0,
          "ttft": 1.374,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.79,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.366,
          "streaming_smoothness": 0.042
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 18:37:46 UTC",
      "results": {
        "Groq": {
          "time": 1.38,
          "status": "Online",
          "tokens_per_second": 396.0,
          "ttft": 0.158,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 11.08,
          "status": "Online",
          "tokens_per_second": 117.0,
          "ttft": 0.98,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.22,
          "status": "Online",
          "tokens_per_second": 69.0,
          "ttft": 1.189,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.5,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 3.31,
          "streaming_smoothness": 0.241
        },
        "DeepSeek": {
          "time": 33.12,
          "status": "Online",
          "tokens_per_second": 38.0,
          "ttft": 3.082,
          "streaming_smoothness": 0.023
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 02:11:03 UTC",
      "results": {
        "Groq": {
          "time": 1.8,
          "status": "Online",
          "tokens_per_second": 375.0,
          "ttft": 0.266,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.83,
          "status": "Online",
          "tokens_per_second": 173.0,
          "ttft": 0.271,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.47,
          "status": "Online",
          "tokens_per_second": 65.0,
          "ttft": 1.042,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.16,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 3.077,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.87,
          "status": "Online",
          "tokens_per_second": 31.0,
          "ttft": 1.378,
          "streaming_smoothness": 0.09
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 06:48:36 UTC",
      "results": {
        "Groq": {
          "time": 1.74,
          "status": "Online",
          "tokens_per_second": 377.0,
          "ttft": 0.225,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 13.09,
          "status": "Online",
          "tokens_per_second": 92.0,
          "ttft": 0.437,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.19,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.137,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.39,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 2.397,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.6,
          "status": "Online",
          "tokens_per_second": 30.0,
          "ttft": 1.27,
          "streaming_smoothness": 0.033
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 13:00:14 UTC",
      "results": {
        "Groq": {
          "time": 2.12,
          "status": "Online",
          "tokens_per_second": 347.0,
          "ttft": 0.276,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.36,
          "status": "Online",
          "tokens_per_second": 127.0,
          "ttft": 0.471,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.23,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 1.478,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 24.11,
          "status": "Online",
          "tokens_per_second": 41.0,
          "ttft": 0.711,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.71,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.107,
          "streaming_smoothness": 0.084
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 18:43:36 UTC",
      "results": {
        "Groq": {
          "time": 1.88,
          "status": "Online",
          "tokens_per_second": 350.0,
          "ttft": 0.271,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.49,
          "status": "Online",
          "tokens_per_second": 195.0,
          "ttft": 0.364,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.68,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 1.341,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.7,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 1.074,
          "streaming_smoothness": 0.47
        },
        "DeepSeek": {
          "time": 32.09,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 0.935,
          "streaming_smoothness": 0.071
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 02:09:54 UTC",
      "results": {
        "Groq": {
          "time": 1.97,
          "status": "Online",
          "tokens_per_second": 416.0,
          "ttft": 0.198,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.4,
          "status": "Online",
          "tokens_per_second": 143.0,
          "ttft": 0.309,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.03,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 2.049,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.46,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.665,
          "streaming_smoothness": 0.51
        },
        "DeepSeek": {
          "time": 38.93,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.506,
          "streaming_smoothness": 0.021
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 06:45:12 UTC",
      "results": {
        "Groq": {
          "time": 1.66,
          "status": "Online",
          "tokens_per_second": 334.0,
          "ttft": 0.258,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.28,
          "status": "Online",
          "tokens_per_second": 157.0,
          "ttft": 0.446,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.87,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 1.486,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 32.11,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 1.192,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 42.03,
          "status": "Online",
          "tokens_per_second": 29.0,
          "ttft": 2.249,
          "streaming_smoothness": 0.061
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    }
  ],
  "reliability_scores": {
    "Groq": 100.0,
    "Together AI": 100.0,
    "OpenAI": 100.0,
    "DeepSeek": 100.0,
    "Mistral AI": 96.7,
    "Anthropic": 0.0,
    "Google": 0.0,
    "Cohere": 0.0,
    "xAI": 0.0,
    "Perplexity": 0.0,
    "Fireworks": 0.0,
    "Cerebras": 0.0
  },
  "metadata": {
    "version": "3.0",
    "parallel_testing": false,
    "streaming_enabled": true,
    "timeout": 90,
    "retries": 3
  }
}