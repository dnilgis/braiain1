{
  "last_updated": "2025-12-14 12:55:05 UTC",
  "prompt": "You are tasked with analyzing the evolution of artificial intelligence from 2010 to 2025. Your response must be comprehensive and well-structured.\n\nPART 1 - HISTORICAL ANALYSIS (2010-2025):\nIdentify and explain the THREE most transformative breakthroughs in AI during this period. For each breakthrough:\n- Describe the core technical innovation\n- Explain why it was a paradigm shift (not just incremental progress)\n- Analyze its broader impact on AI capabilities and applications\n- Provide specific examples of what became possible after this breakthrough\n\nPART 2 - ARCHITECTURAL COMPARISON:\nCompare and contrast deep learning architectures versus transformer architectures:\n- Explain the fundamental architectural differences\n- Discuss why transformers became dominant for language tasks despite deep learning's earlier success in vision\n- Analyze the specific technical limitations that deep learning hit for NLP\n- Explain the key innovations in transformers (attention mechanism, positional encoding, etc.) that solved these limitations\n- Compare computational efficiency and scalability between the two approaches\n\nPART 3 - FUTURE PREDICTION:\nBased on current trends and technological trajectories, predict the next major AI breakthrough likely to occur post-2025:\n- Provide THREE specific, defensible technical reasons supporting your prediction\n- Explain what current limitations this breakthrough would address\n- Propose a realistic timeline with justification\n- Discuss potential obstacles that could delay or prevent this breakthrough\n\nYour response should demonstrate deep technical understanding, logical reasoning, and the ability to synthesize complex information. Aim for 2500-3500 characters with clear structure and specific technical details.",
  "max_tokens": 1000,
  "results": [
    {
      "provider": "Groq",
      "model": "llama-3.3-70b-versatile",
      "status": "Online",
      "time": 1.74,
      "ttft": 0.212,
      "tokens_per_second": 390.0,
      "streaming_smoothness": 0,
      "output_tokens": 679,
      "character_count": 2719,
      "cost_per_request": 0.0,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1. **Deep Learning (2010)**: Core technical innovation was the use of convolutional neural networks (CNNs) and recurrent neural networks (RNNs) for image and speech recognition. This was a paradigm shift as it enabled AI to learn complex patterns from large datasets, leading to state-of-the-art performance in image classification and speech recognition. Broader impact: enabled applications like self-driving cars and personal assistants. Examples: ImageNet, Siri.\n\n2. **Generative Adversarial Networks (GANs) (2014)**: Introduced a new framework for generative models, allowing AI to generate realistic images, videos, and text. Paradigm shift: enabled AI to create new content, not just recognize patterns. Broader impact: enabled applications like AI-generated art, synthetic data generation, and text-to-image synthesis. Examples: AI-generated portraits, Deepfakes.\n\n3. **Transformer Architecture (2017)**: Introduced self-attention mechanisms for sequence-to-sequence tasks, revolutionizing natural language processing (NLP). Paradigm shift: enabled AI to handle long-range dependencies and contextual relationships in language. Broader impact: enabled state-of-the-art performance in machine translation, text summarization, and question answering. Examples: BERT, RoBERTa.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\nDeep learning architectures (CNNs, RNNs) relies on convolutional and recurrent layers, whereas transformer architectures rely on self-attention mechanisms. Transformers became dominant for NLP tasks due to their ability to handle long-range dependencies and contextual relationships. Deep learning hit limitations in NLP due to its reliance on recurrent layers, which struggled with vanishing gradients and long-term dependencies. Transformers introduced key innovations like attention mechanisms and positional encoding, enabling more efficient and scalable processing of sequential data. Transformers have better computational efficiency and scalability than deep learning architectures for NLP tasks.\n\n**PART 3 - FUTURE PREDICTION**\n\nNext major AI breakthrough: **Explainable AI (XAI)**. Three technical reasons: (1) increasing demand for transparency and accountability in AI decision-making, (2) advancements in attention mechanisms and saliency maps, and (3) integration of cognitive architectures and multimodal learning. This breakthrough would address current limitations in AI interpretability and trustworthiness. Realistic timeline: 2028-2032, driven by advancements in XAI research and increasing regulatory pressures. Potential obstacles: complexity of AI models, lack of standardization, and balancing interpretability with performance.",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1. **Deep Learning (2010)**: Core technical innovation was the use of convolutional neural networks (CNNs) and recurrent neural networks (RNNs) for image ...",
      "error_info": null
    },
    {
      "provider": "Together AI",
      "model": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
      "status": "Online",
      "time": 6.98,
      "ttft": 0.214,
      "tokens_per_second": 195.0,
      "streaming_smoothness": 0,
      "output_tokens": 1363,
      "character_count": 5455,
      "cost_per_request": 0.00159,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\nThe period from 2010 to 2025 witnessed significant advancements in artificial intelligence, transforming the field in profound ways. Here are the three most transformative breakthroughs during this period:\n\n1. **Convolutional Neural Networks (CNNs) for Image Recognition (2012)**\n\nCore technical innovation: CNNs utilize convolutional and pooling layers to extract features from images.\n\nParadigm shift: This breakthrough marked a shift from traditional, hand-engineered feature extraction techniques to end-to-end, deep learning-based image recognition.\n\nBroader impact: CNNs enabled significant advancements in image classification, object detection, and segmentation, leading to applications in self-driving cars, surveillance, and healthcare.\n\nPossible only after this breakthrough: Facebook's facial recognition technology, Google's self-driving cars, and medical image analysis for diagnosis.\n\n2. **Bidirectional Encoder Representations from Transformers (BERT) for Natural Language Processing (2018)**\n\nCore technical innovation: BERT employs a multi-layer bidirectional transformer encoder to learn contextualized representations of words in a sentence.\n\nParadigm shift: This breakthrough transitioned NLP from primarily focusing on task-specific, trained-from-scratch models to leveraging pre-trained, general-purpose language models.\n\nBroader impact: BERT-like models revolutionized NLP by achieving state-of-the-art results in various tasks, including question answering, sentiment analysis, and language translation.\n\nPossible only after this breakthrough: Google's improved search results, virtual assistants like Siri and Alexa, and more accurate machine translation systems.\n\n3. **Generative Adversarial Networks (GANs) for Generative Modeling (2014)**\n\nCore technical innovation: GANs introduce an adversarial framework where a generator competes with a discriminator to produce realistic data samples.\n\nParadigm shift: This breakthrough shifted the focus from primarily discriminative models (i.e., models that predict a label) to generative models that can create new data.\n\nBroader impact: GANs have been applied to various domains, such as image and video generation, data augmentation, and unsupervised learning.\n\nPossible only after this breakthrough: Deepfake videos, AI-generated artwork, and synthetic data for training AI models.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\nDeep learning architectures were initially dominant in AI, especially for vision tasks. However, transformer architectures later became the preferred choice for NLP tasks. Here's a comparison of the two:\n\n**Fundamental architectural differences:**\n\n* Deep learning architectures primarily rely on convolutional and recurrent neural networks (CNNs and RNNs) to process sequential data.\n* Transformer architectures are built around self-attention mechanisms, which allow for parallel processing and better capture long-range dependencies in sequential data.\n\n**Why transformers dominate NLP:**\n\n* Deep learning architectures hit limitations in NLP due to their inability to effectively capture long-range dependencies, context, and complexity in sequential data.\n* The self-attention mechanism in transformer architectures allows for parallel processing, reducing computational requirements and enabling more efficient training.\n\n**Key innovations in transformers:**\n\n* Attention mechanism: allows the model to focus on different parts of the input data when generating output.\n* Positional encoding: enables the model to capture the order of input data, a crucial aspect in sequential data processing.\n\n**Computational efficiency and scalability:**\n\n* Transformers generally require more computational resources than deep learning architectures due to the self-attention mechanism.\n* However, recent advancements in efficient transformer architectures and large-scale training techniques have improved their scalability.\n\n**PART 3 - FUTURE PREDICTION**\n\nBased on current trends and technological trajectories, the next major AI breakthrough likely to occur post-2025 is the development of **Cognitive Architectures that Integrate Symbolic and Connectionist AI.**\n\n**Three specific, defensible technical reasons supporting this prediction:**\n\n1. **Increasing complexity in AI systems:** As AI models become more complex and multi-modal, integrating symbolic and connectionist AI will enable more robust and explainable decision-making.\n2. **Need for hybrid learning approaches:** Combining the strengths of symbolic AI (reasoning and knowledge representation) with connectionist AI (pattern recognition and learning from data) will lead to more powerful and flexible AI systems.\n3. **Advances in cognitive architectures and neurosymbolic AI:** Recent research in cognitive architectures and neurosymbolic AI has laid the groundwork for integrating symbolic and connectionist AI, paving the way for more sophisticated AI systems.\n\n**Current limitations addressed:**\n\n* Current AI systems often lack common sense, reasoning, and explainability, which can be addressed by integrating symbolic AI.\n* The integration of symbolic and connectionist AI will also enable more efficient and effective knowledge representation and transfer.\n\n**Proposed timeline with justification:**\n\n* 2025-2030: Development of hybrid learning approaches and cognitive architectures that integrate symbolic and connectionist AI.\n* 2030-2035:",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\nThe period from 2010 to 2025 witnessed significant advancements in artificial intelligence, transforming the field in profound ways. Here are the three mo...",
      "error_info": null
    },
    {
      "provider": "Mistral AI",
      "model": "mistral-large-latest",
      "status": "Online",
      "time": 19.2,
      "ttft": 0.451,
      "tokens_per_second": 52.0,
      "streaming_smoothness": 0,
      "output_tokens": 994,
      "character_count": 3977,
      "cost_per_request": 0.00684,
      "full_response": "# **The Evolution of Artificial Intelligence (2010\u20132025): A Comprehensive Analysis**\n\n## **PART 1 \u2013 HISTORICAL ANALYSIS (2010\u20132025): Three Transformative Breakthroughs**\n\n### **1. Deep Learning Revolution (2012\u20132015): The Rise of Neural Networks**\n#### **Core Technical Innovation**\nThe breakthrough in deep learning was the **effective training of deep neural networks (DNNs)** using:\n- **Rectified Linear Units (ReLU)** \u2013 Solved the vanishing gradient problem, enabling deeper networks.\n- **Convolutional Neural Networks (CNNs)** \u2013 Specialized for spatial data (e.g., images), using hierarchical feature extraction.\n- **Large-scale labeled datasets (ImageNet)** \u2013 Provided the training data necessary for supervised learning at scale.\n- **GPU acceleration** \u2013 Enabled parallel computation, drastically reducing training time.\n\n#### **Paradigm Shift**\nBefore 2012, AI relied on **handcrafted features** (e.g., SIFT, HOG) and shallow machine learning models (SVMs, decision trees). Deep learning **automated feature extraction**, eliminating the need for domain-specific engineering. The **2012 AlexNet** victory in the ImageNet competition (15.3% error vs. 26.2% for traditional methods) marked the shift from feature engineering to **end-to-end learning**.\n\n#### **Broader Impact**\n- **Computer Vision:** Enabled real-time object detection (YOLO, Faster R-CNN), facial recognition (DeepFace), and medical imaging (tumor detection).\n- **Speech Recognition:** Deep learning replaced Gaussian Mixture Models (GMMs) with **LSTMs and CNNs**, improving accuracy in systems like Siri and Google Assistant.\n- **Autonomous Systems:** Tesla\u2019s Autopilot (2014) and Waymo\u2019s self-driving cars leveraged CNNs for perception.\n- **Generative Models:** Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) emerged, enabling deepfakes, synthetic data generation, and artistic AI (e.g., DALL\u00b7E\u2019s precursors).\n\n#### **What Became Possible?**\n- **Real-time image classification** (e.g., Google Photos\u2019 search-by-image).\n- **Superhuman performance in narrow tasks** (e.g., AlphaGo beating Lee Sedol in 2016).\n- **Transfer learning** \u2013 Pre-trained models (e.g., VGG, ResNet) could be fine-tuned for new tasks with minimal data.\n\n---\n\n### **2. Transformer Architecture (2017\u20132020): The Attention Revolution**\n#### **Core Technical Innovation**\nThe **Transformer** (Vaswani et al., 2017) introduced:\n- **Self-attention mechanism** \u2013 Dynamically weighs input tokens based on relevance, enabling **parallel processing** (unlike RNNs/LSTMs).\n- **Positional encoding** \u2013 Preserves sequence order without recurrence.\n- **Multi-head attention** \u2013 Allows the model to focus on different parts of the input simultaneously.\n- **Scalability** \u2013 Unlike RNNs, Transformers could be **parallelized** across GPUs/TPUs, enabling massive models (e.g., BERT, GPT-3).\n\n#### **Paradigm Shift**\nBefore Transformers, **Recurrent Neural Networks (RNNs) and LSTMs** dominated NLP, but suffered from:\n- **Sequential processing** \u2013 Slow training due to dependency on previous tokens.\n- **Long-term dependency loss** \u2013 Struggled with long-range context (e.g., \"The cat, which was very hungry, walked across the room\u2026\").\n- **Limited parallelization** \u2013 Training was bottlenecked by sequential data flow.\n\nTransformers **eliminated recurrence**, allowing **full parallelization** and **arbitrary-length context** (via attention). The **2018 BERT model** (Bidirectional Encoder Representations from Transformers) achieved state-of-the-art results in **11 NLP tasks** by pre-training on massive unlabeled text, then fine-tuning.\n\n#### **Broader Impact**\n- **Natural Language Processing (NLP):**\n  - **Question Answering** (e.g., Google Search, SQuAD benchmark).\n  - **Machine Translation** (e.g., Google Translate, DeepL).\n  - **Text Generation** (e.g., GPT-3, ChatGPT, code generation with GitHub Copilot).\n- **Multimodal AI:**\n  - **Vision Transformers (ViT, 2020)** \u2013 Applied attention to images, rivaling",
      "response_preview": "# **The Evolution of Artificial Intelligence (2010\u20132025): A Comprehensive Analysis**\n\n## **PART 1 \u2013 HISTORICAL ANALYSIS (2010\u20132025): Three Transformative Breakthroughs**\n\n### **1. Deep Learning Revolu...",
      "error_info": null
    },
    {
      "provider": "OpenAI",
      "model": "gpt-4o-mini",
      "status": "Online",
      "time": 22.05,
      "ttft": 1.469,
      "tokens_per_second": 61.0,
      "streaming_smoothness": 0,
      "output_tokens": 1352,
      "character_count": 5409,
      "cost_per_request": 0.00088,
      "full_response": "## PART 1 - HISTORICAL ANALYSIS (2010-2025)\n\n### Breakthrough 1: Deep Learning and Neural Networks\n- **Core Technical Innovation**: The resurgence of deep learning techniques, particularly Convolutional Neural Networks (CNNs), enabled computers to learn representations of data through multiple layers of abstraction.\n- **Paradigm Shift**: Prior to this, classical machine learning approached the problem of feature extraction manually, which required domain expertise and was limited in capacity. Deep learning automatically discovered intricate features from raw data, revolutionizing how AI models were trained.\n- **Broader Impact**: This led to significant advancements in image and speech recognition. Deep learning became the bedrock for a variety of applications such as facial recognition in social media platforms and voice assistants like Siri and Google Assistant. \n- **Examples of New Possibilities**: ImageNet breakthrough in 2012 demonstrated that deep learning could outperform traditional methods in image classification, which paved the way for its subsequent adoption in autonomous vehicles and medical imaging.\n\n### Breakthrough 2: Natural Language Processing (NLP) with RNNs and LSTMs\n- **Core Technical Innovation**: The development of Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks allowed models to maintain context over sequences of data, making them essential for tasks like language modeling and translation.\n- **Paradigm Shift**: Before RNNs, text processing often utilized bag-of-words or simple n-gram models, which lost contextual information. LSTMs could remember information for extended sequences, transforming how machines interpreted human language.\n- **Broader Impact**: This led to improved machine translation services (e.g., Google Translate) and sentiment analysis in understanding text data. \n- **Examples of New Possibilities**: Applications in chatbots, allowing for more natural and contextually aware conversation flows, and predictive text features in smartphones.\n\n### Breakthrough 3: The Transformer Model\n- **Core Technical Innovation**: Introduced in the paper \u201cAttention is All You Need\u201d (2017), the transformer architecture utilized self-attention mechanisms to process entire sequences simultaneously, removing the RNN limitation of sequential data processing.\n- **Paradigm Shift**: Unlike previous models that required sequential processing and suffered from long-range dependency issues, transformers provided parallelization, significantly speeding up training and improving performance on long context tasks.\n- **Broader Impact**: Transformers established new state-of-the-art performance in various NLP tasks and gave rise to a plethora of models capable of understanding and generating human-like text.\n- **Examples of New Possibilities**: BERT revolutionized search engines with improved understanding of context in user queries, and GPT-2/3 redefined capabilities in text generation, creative writing, and code synthesis.\n\n## PART 2 - ARCHITECTURAL COMPARISON\n\n### Fundamental Architectural Differences\n- **Deep Learning Architectures**: Primarily rely on layers of neurons arranged in feedforward, convolutional, or recurrent setups, focusing heavily on hierarchical feature extraction.\n- **Transformer Architectures**: Use self-attention layers that allow direct connections between every token in the input sequence without relying on sequential processing.\n\n### Dominance for Language Tasks\n- Transformers overtook deep learning's success in vision due to the inherent nature of language, which benefits from understanding contextual relationships across entire sequences rather than just spatial hierarchies.\n\n### Limitations of Deep Learning in NLP\n- Deep learning architectures, especially RNNs, faced challenges with long-term dependencies and sequential processing bottlenecks, leading to difficulties in handling complex language structures.\n\n### Innovations in Transformers\n- **Attention Mechanism**: Allows the model to weigh the importance of different words relative to each other irrespective of their position, effectively capturing relationships in language.\n- **Positional Encoding**: Addresses the limitation of order information lost in self-attention by encoding the position of each token, allowing the model to understand sequence order.\n\n### Computational Efficiency and Scalability\n- **Deep Learning**: Typically expensive due to sequential processing of data (in RNNs) and requires extensive training data.\n- **Transformers**: Can efficiently handle massive parallelization of computations and scale to larger datasets, leading to training models with billions of parameters effectively.\n\n## PART 3 - FUTURE PREDICTION\n\n### Predicted Breakthrough: General Intelligence through Hybrid Models\n- **Technical Reasons**:\n  1. **Integration of Multimodal Learning**: The convergence of visual, auditory, and text data processing using unified models will enhance understanding of complex tasks.\n  2. **Meta-Learning**: Algorithms that can learn how to learn will enable models to adapt quickly to new tasks with minimal data.\n  3. **Continual Learning**: More robust architectures that retain knowledge over time without catastrophic forgetting will contribute towards building more intelligent systems.\n\n### Current Limitations Addressed\nThese breakthroughs will alleviate difficulties like general",
      "response_preview": "## PART 1 - HISTORICAL ANALYSIS (2010-2025)\n\n### Breakthrough 1: Deep Learning and Neural Networks\n- **Core Technical Innovation**: The resurgence of deep learning techniques, particularly Convolution...",
      "error_info": null
    },
    {
      "provider": "DeepSeek",
      "model": "deepseek-chat",
      "status": "Online",
      "time": 38.87,
      "ttft": 1.213,
      "tokens_per_second": 33.0,
      "streaming_smoothness": 0.026,
      "output_tokens": 1269,
      "character_count": 5077,
      "cost_per_request": 0.00042,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1.  **Deep Learning's Dominance (c. 2012):** The core innovation was the effective training of very deep convolutional neural networks (CNNs) using GPUs, backpropagation, and techniques like ReLU and Dropout. This was a paradigm shift from hand-engineered features to learned hierarchical representations. It enabled superhuman performance in image classification (AlexNet on ImageNet), revolutionizing computer vision and enabling applications from medical imaging to autonomous vehicle perception.\n\n2.  **The Transformer Architecture (2017):** The innovation was the scaled dot-product attention mechanism, which allowed the model to weigh the importance of all parts of an input sequence simultaneously, and positional encoding, which injected sequence order without recurrence. This shifted NLP from sequential (RNN/LSTM) processing to parallelizable context modeling. It made large-scale pre-training feasible, leading directly to models like BERT (bidirectional context) and GPT (generative capability), enabling coherent long-form text generation and sophisticated language understanding.\n\n3.  **Large Language Model Emergence & Scaling Laws (2020 onward):** The breakthrough was the empirical discovery of predictable scaling laws\u2014that model performance scales predictably with parameters, compute, and data. This shifted AI from task-specific models to \"pre-train and adapt\" general-purpose foundations. It led to capable few-shot learners (GPT-3) and later multimodal systems (GPT-4), enabling conversational AI, code generation, and reasoning across domains without task-specific architecture changes.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\n**Fundamental Differences:** Deep learning (here meaning CNNs/RNNs) relies on local, inductive biases: CNNs use convolutional filters for spatial locality and translation invariance; RNNs process sequences step-by-step, maintaining a hidden state. Transformers use **self-attention**, which creates global, dynamic connections across the entire input sequence in a single layer, with no inherent notion of locality or sequential order.\n\n**Dominance in NLP:** CNNs excelled in vision due to their spatial hierarchy mirroring the world. RNNs, the prior NLP standard, hit critical limitations: sequential processing prevented parallelization, making training slow, and they struggled with **long-range dependencies** due to vanishing gradients. The attention mechanism in RNNs (e.g., Bahdanau attention) was a precursor but applied only to encoder-decoder contexts.\n\n**Transformer Innovations & Solutions:**\n*   **Self-Attention:** Solves the long-range dependency problem by directly computing relationships between all tokens, regardless of distance, in parallel.\n*   **Positional Encoding:** Injects sequence order information (via sine/cosine functions or learned embeddings) since attention alone is permutation-invariant.\n*   **Layer Stacking & Feed-Forward Networks:** Enables complex, non-linear transformations of attended representations.\n\n**Computational Efficiency & Scalability:** For sequence length *N*, self-attention has *O(N\u00b2)* complexity in memory and time, which becomes a bottleneck for very long sequences. However, it is massively **parallelizable** within a training step, unlike RNNs' *O(N)* sequential steps. This parallelizability, combined with optimized hardware (GPUs/TPUs), made training on enormous datasets feasible, enabling scaling laws. CNNs have *O(k*N)* complexity for kernel size *k* but are limited to local contexts unless deeply stacked.\n\n**PART 3 - FUTURE PREDICTION**\n\n**Prediction:** The next major breakthrough will be the widespread adoption of **highly sample-efficient, planning-based hybrid architectures** (neuro-symbolic or world-model-based) that move beyond next-token prediction to achieve robust, verifiable reasoning.\n\n**Three Technical Reasons:**\n1.  **Crisis of Scale:** Diminishing returns from pure data/compute scaling are becoming evident. Future gains require more efficient algorithmic abstractions.\n2.  **Reasoning Deficits:** Current LLMs struggle with consistent multi-step planning, precise logical deduction, and counterfactual reasoning, hallmarks of true cognition.\n3.  **Verification Need:** Critical applications (science, medicine, safety) require traceable, verifiable reasoning chains, not just statistically plausible outputs.\n\n**Limitations Addressed:** This would address poor out-of-distribution generalization, factual inconsistency, and the inability to perform novel, complex task planning without vast training data.\n\n**Realistic Timeline & Justification:** Foundational research is active (e.g., AlphaGeometry, LLM-guided symbolic solvers). We will see research prototypes by 2027-2028, with mature industrial applications by 2030. The timeline is set by the need to integrate slow, deliberate symbolic search with fast neural intuition\u2014a significant engineering and theoretical challenge.\n\n**Potential Obstacles:**\n*   **Integration Complexity:** Creating seamless, trainable interfaces between",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1.  **Deep Learning's Dominance (c. 2012):** The core innovation was the effective training of very deep convolutional neural networks (CNNs) using GPUs, ...",
      "error_info": null
    },
    {
      "provider": "Anthropic",
      "model": "claude-3-5-sonnet-20241022",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-14 12:53:23 UTC"
      }
    },
    {
      "provider": "Google",
      "model": "gemini-1.5-flash",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-14 12:53:31 UTC"
      }
    },
    {
      "provider": "Cohere",
      "model": "command-r-plus",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-14 12:54:01 UTC"
      }
    },
    {
      "provider": "Fireworks",
      "model": "accounts/fireworks/models/llama-v3p1-70b-instruct",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-14 12:54:56 UTC"
      }
    },
    {
      "provider": "Cerebras",
      "model": "llama3.1-70b",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-14 12:55:04 UTC"
      }
    }
  ],
  "history": [
    {
      "timestamp": "2025-12-07 06:39:23 UTC",
      "results": {
        "Groq": {
          "time": 1.54,
          "status": "Online",
          "tokens_per_second": 336.0,
          "ttft": 0.197,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.86,
          "status": "Online",
          "tokens_per_second": 144.0,
          "ttft": 0.436,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 16.83,
          "status": "Online",
          "tokens_per_second": 80.0,
          "ttft": 1.303,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.56,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 1.576,
          "streaming_smoothness": 0.067
        },
        "DeepSeek": {
          "time": 34.65,
          "status": "Online",
          "tokens_per_second": 36.0,
          "ttft": 1.226,
          "streaming_smoothness": 0.065
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 12:52:59 UTC",
      "results": {
        "Groq": {
          "time": 1.45,
          "status": "Online",
          "tokens_per_second": 350.0,
          "ttft": 0.143,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.81,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.291,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.96,
          "status": "Online",
          "tokens_per_second": 49.0,
          "ttft": 0.471,
          "streaming_smoothness": 0.799
        },
        "OpenAI": {
          "time": 22.43,
          "status": "Online",
          "tokens_per_second": 61.0,
          "ttft": 1.374,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.79,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.366,
          "streaming_smoothness": 0.042
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 18:37:46 UTC",
      "results": {
        "Groq": {
          "time": 1.38,
          "status": "Online",
          "tokens_per_second": 396.0,
          "ttft": 0.158,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 11.08,
          "status": "Online",
          "tokens_per_second": 117.0,
          "ttft": 0.98,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.22,
          "status": "Online",
          "tokens_per_second": 69.0,
          "ttft": 1.189,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.5,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 3.31,
          "streaming_smoothness": 0.241
        },
        "DeepSeek": {
          "time": 33.12,
          "status": "Online",
          "tokens_per_second": 38.0,
          "ttft": 3.082,
          "streaming_smoothness": 0.023
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 02:11:03 UTC",
      "results": {
        "Groq": {
          "time": 1.8,
          "status": "Online",
          "tokens_per_second": 375.0,
          "ttft": 0.266,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.83,
          "status": "Online",
          "tokens_per_second": 173.0,
          "ttft": 0.271,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.47,
          "status": "Online",
          "tokens_per_second": 65.0,
          "ttft": 1.042,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.16,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 3.077,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.87,
          "status": "Online",
          "tokens_per_second": 31.0,
          "ttft": 1.378,
          "streaming_smoothness": 0.09
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 06:48:36 UTC",
      "results": {
        "Groq": {
          "time": 1.74,
          "status": "Online",
          "tokens_per_second": 377.0,
          "ttft": 0.225,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 13.09,
          "status": "Online",
          "tokens_per_second": 92.0,
          "ttft": 0.437,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.19,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.137,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.39,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 2.397,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.6,
          "status": "Online",
          "tokens_per_second": 30.0,
          "ttft": 1.27,
          "streaming_smoothness": 0.033
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 13:00:14 UTC",
      "results": {
        "Groq": {
          "time": 2.12,
          "status": "Online",
          "tokens_per_second": 347.0,
          "ttft": 0.276,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.36,
          "status": "Online",
          "tokens_per_second": 127.0,
          "ttft": 0.471,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.23,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 1.478,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 24.11,
          "status": "Online",
          "tokens_per_second": 41.0,
          "ttft": 0.711,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.71,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.107,
          "streaming_smoothness": 0.084
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 18:43:36 UTC",
      "results": {
        "Groq": {
          "time": 1.88,
          "status": "Online",
          "tokens_per_second": 350.0,
          "ttft": 0.271,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.49,
          "status": "Online",
          "tokens_per_second": 195.0,
          "ttft": 0.364,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.68,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 1.341,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.7,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 1.074,
          "streaming_smoothness": 0.47
        },
        "DeepSeek": {
          "time": 32.09,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 0.935,
          "streaming_smoothness": 0.071
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 02:09:54 UTC",
      "results": {
        "Groq": {
          "time": 1.97,
          "status": "Online",
          "tokens_per_second": 416.0,
          "ttft": 0.198,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.4,
          "status": "Online",
          "tokens_per_second": 143.0,
          "ttft": 0.309,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.03,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 2.049,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.46,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.665,
          "streaming_smoothness": 0.51
        },
        "DeepSeek": {
          "time": 38.93,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.506,
          "streaming_smoothness": 0.021
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 06:45:12 UTC",
      "results": {
        "Groq": {
          "time": 1.66,
          "status": "Online",
          "tokens_per_second": 334.0,
          "ttft": 0.258,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.28,
          "status": "Online",
          "tokens_per_second": 157.0,
          "ttft": 0.446,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.87,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 1.486,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 32.11,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 1.192,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 42.03,
          "status": "Online",
          "tokens_per_second": 29.0,
          "ttft": 2.249,
          "streaming_smoothness": 0.061
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 13:02:20 UTC",
      "results": {
        "Groq": {
          "time": 1.69,
          "status": "Online",
          "tokens_per_second": 388.0,
          "ttft": 0.153,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.25,
          "status": "Online",
          "tokens_per_second": 190.0,
          "ttft": 0.35,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.22,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.225,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 26.15,
          "status": "Online",
          "tokens_per_second": 37.0,
          "ttft": 3.278,
          "streaming_smoothness": 0.494
        },
        "DeepSeek": {
          "time": 38.27,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.353,
          "streaming_smoothness": 0.037
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 18:39:45 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 365.0,
          "ttft": 0.168,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.55,
          "status": "Online",
          "tokens_per_second": 151.0,
          "ttft": 0.651,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 23.07,
          "status": "Online",
          "tokens_per_second": 64.0,
          "ttft": 1.297,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 26.09,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 1.506,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 31.69,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.187,
          "streaming_smoothness": 0.077
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 02:11:51 UTC",
      "results": {
        "Groq": {
          "time": 1.75,
          "status": "Online",
          "tokens_per_second": 403.0,
          "ttft": 0.366,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.22,
          "status": "Online",
          "tokens_per_second": 207.0,
          "ttft": 0.582,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.95,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 2.078,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 25.37,
          "status": "Online",
          "tokens_per_second": 55.0,
          "ttft": 1.827,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.45,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.231,
          "streaming_smoothness": 0.093
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 06:45:39 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 376.0,
          "ttft": 0.189,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.16,
          "status": "Online",
          "tokens_per_second": 146.0,
          "ttft": 0.333,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.43,
          "status": "Online",
          "tokens_per_second": 50.0,
          "ttft": 1.996,
          "streaming_smoothness": 0.299
        },
        "OpenAI": {
          "time": 26.86,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.981,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.07,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.192,
          "streaming_smoothness": 0.027
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 13:02:42 UTC",
      "results": {
        "Groq": {
          "time": 1.36,
          "status": "Online",
          "tokens_per_second": 325.0,
          "ttft": 0.205,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.29,
          "status": "Online",
          "tokens_per_second": 147.0,
          "ttft": 0.31,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.6,
          "status": "Online",
          "tokens_per_second": 42.0,
          "ttft": 1.082,
          "streaming_smoothness": 0.488
        },
        "OpenAI": {
          "time": 24.1,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 1.467,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.88,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.121,
          "streaming_smoothness": 0.109
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 18:42:03 UTC",
      "results": {
        "Groq": {
          "time": 1.7,
          "status": "Online",
          "tokens_per_second": 379.0,
          "ttft": 0.269,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.25,
          "status": "Online",
          "tokens_per_second": 178.0,
          "ttft": 0.217,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.84,
          "status": "Online",
          "tokens_per_second": 60.0,
          "ttft": 1.331,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.92,
          "status": "Online",
          "tokens_per_second": 48.0,
          "ttft": 0.509,
          "streaming_smoothness": 0.258
        },
        "DeepSeek": {
          "time": 31.5,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.568,
          "streaming_smoothness": 0.1
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 02:13:30 UTC",
      "results": {
        "Groq": {
          "time": 1.5,
          "status": "Online",
          "tokens_per_second": 380.0,
          "ttft": 0.201,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.78,
          "status": "Online",
          "tokens_per_second": 146.0,
          "ttft": 0.258,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 18.95,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 1.227,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.36,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 0.479,
          "streaming_smoothness": 0.496
        },
        "DeepSeek": {
          "time": 39.35,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.931,
          "streaming_smoothness": 0.099
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 06:47:15 UTC",
      "results": {
        "Groq": {
          "time": 1.54,
          "status": "Online",
          "tokens_per_second": 356.0,
          "ttft": 0.257,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.7,
          "status": "Online",
          "tokens_per_second": 206.0,
          "ttft": 0.307,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.5,
          "status": "Online",
          "tokens_per_second": 42.0,
          "ttft": 0.509,
          "streaming_smoothness": 0.525
        },
        "OpenAI": {
          "time": 24.47,
          "status": "Online",
          "tokens_per_second": 58.0,
          "ttft": 0.985,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.04,
          "status": "Online",
          "tokens_per_second": 31.0,
          "ttft": 1.5,
          "streaming_smoothness": 0.113
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 13:03:57 UTC",
      "results": {
        "Groq": {
          "time": 1.6,
          "status": "Online",
          "tokens_per_second": 332.0,
          "ttft": 0.298,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.11,
          "status": "Online",
          "tokens_per_second": 152.0,
          "ttft": 0.53,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.29,
          "status": "Online",
          "tokens_per_second": 53.0,
          "ttft": 0.741,
          "streaming_smoothness": 0.691
        },
        "OpenAI": {
          "time": 22.25,
          "status": "Online",
          "tokens_per_second": 62.0,
          "ttft": 1.406,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.62,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.423,
          "streaming_smoothness": 0.093
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 18:42:55 UTC",
      "results": {
        "Groq": {
          "time": 1.35,
          "status": "Online",
          "tokens_per_second": 370.0,
          "ttft": 0.196,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 14.46,
          "status": "Online",
          "tokens_per_second": 91.0,
          "ttft": 0.482,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.23,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.489,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.77,
          "status": "Online",
          "tokens_per_second": 69.0,
          "ttft": 1.935,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 32.35,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.178,
          "streaming_smoothness": 0.006
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 02:13:32 UTC",
      "results": {
        "Groq": {
          "time": 1.67,
          "status": "Online",
          "tokens_per_second": 343.0,
          "ttft": 0.193,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.98,
          "status": "Online",
          "tokens_per_second": 113.0,
          "ttft": 0.698,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.82,
          "status": "Online",
          "tokens_per_second": 56.0,
          "ttft": 0.733,
          "streaming_smoothness": 0.107
        },
        "OpenAI": {
          "time": 20.16,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.33,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.35,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.392,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 06:45:53 UTC",
      "results": {
        "Groq": {
          "time": 1.83,
          "status": "Online",
          "tokens_per_second": 452.0,
          "ttft": 0.205,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.83,
          "status": "Online",
          "tokens_per_second": 162.0,
          "ttft": 0.603,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.15,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.673,
          "streaming_smoothness": 0.26
        },
        "OpenAI": {
          "time": 27.03,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 1.562,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.38,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.421,
          "streaming_smoothness": 0.045
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 13:00:50 UTC",
      "results": {
        "Groq": {
          "time": 1.77,
          "status": "Online",
          "tokens_per_second": 423.0,
          "ttft": 0.186,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.7,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.41,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.84,
          "status": "Online",
          "tokens_per_second": 64.0,
          "ttft": 1.433,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 24.34,
          "status": "Online",
          "tokens_per_second": 38.0,
          "ttft": 0.747,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 37.37,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.349,
          "streaming_smoothness": 0.121
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 18:42:55 UTC",
      "results": {
        "Groq": {
          "time": 1.64,
          "status": "Online",
          "tokens_per_second": 363.0,
          "ttft": 0.129,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.92,
          "status": "Online",
          "tokens_per_second": 148.0,
          "ttft": 0.468,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.48,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 0.49,
          "streaming_smoothness": 0.041
        },
        "OpenAI": {
          "time": 23.98,
          "status": "Online",
          "tokens_per_second": 58.0,
          "ttft": 1.461,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 31.27,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 1.173,
          "streaming_smoothness": 0.096
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 02:06:27 UTC",
      "results": {
        "Groq": {
          "time": 1.81,
          "status": "Online",
          "tokens_per_second": 352.0,
          "ttft": 0.28,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 13.11,
          "status": "Online",
          "tokens_per_second": 136.0,
          "ttft": 0.466,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.85,
          "status": "Online",
          "tokens_per_second": 53.0,
          "ttft": 0.757,
          "streaming_smoothness": 0.299
        },
        "OpenAI": {
          "time": 26.05,
          "status": "Online",
          "tokens_per_second": 52.0,
          "ttft": 1.229,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 36.91,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 1.277,
          "streaming_smoothness": 0.017
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 06:41:23 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 340.0,
          "ttft": 0.155,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.27,
          "status": "Online",
          "tokens_per_second": 148.0,
          "ttft": 0.304,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.18,
          "status": "Online",
          "tokens_per_second": 59.0,
          "ttft": 0.444,
          "streaming_smoothness": 0.303
        },
        "OpenAI": {
          "time": 20.83,
          "status": "Online",
          "tokens_per_second": 66.0,
          "ttft": 1.398,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.67,
          "status": "Online",
          "tokens_per_second": 36.0,
          "ttft": 1.269,
          "streaming_smoothness": 0.002
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 12:55:08 UTC",
      "results": {
        "Groq": {
          "time": 1.9,
          "status": "Online",
          "tokens_per_second": 383.0,
          "ttft": 0.259,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.56,
          "status": "Online",
          "tokens_per_second": 175.0,
          "ttft": 0.581,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.28,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.504,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.47,
          "status": "Online",
          "tokens_per_second": 66.0,
          "ttft": 1.223,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.51,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 2.058,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 18:37:33 UTC",
      "results": {
        "Groq": {
          "time": 1.86,
          "status": "Online",
          "tokens_per_second": 347.0,
          "ttft": 0.2,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.25,
          "status": "Online",
          "tokens_per_second": 147.0,
          "ttft": 0.457,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 16.28,
          "status": "Online",
          "tokens_per_second": 82.0,
          "ttft": 1.146,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.75,
          "status": "Online",
          "tokens_per_second": 53.0,
          "ttft": 0.689,
          "streaming_smoothness": 0.135
        },
        "DeepSeek": {
          "time": 31.38,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 1.383,
          "streaming_smoothness": 0.102
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-14 02:25:59 UTC",
      "results": {
        "Groq": {
          "time": 1.42,
          "status": "Online",
          "tokens_per_second": 385.0,
          "ttft": 0.159,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.33,
          "status": "Online",
          "tokens_per_second": 169.0,
          "ttft": 0.35,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.12,
          "status": "Online",
          "tokens_per_second": 52.0,
          "ttft": 0.455,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 23.38,
          "status": "Online",
          "tokens_per_second": 59.0,
          "ttft": 1.13,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.4,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 1.169,
          "streaming_smoothness": 0.08
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-14 06:41:31 UTC",
      "results": {
        "Groq": {
          "time": 1.4,
          "status": "Online",
          "tokens_per_second": 334.0,
          "ttft": 0.247,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.16,
          "status": "Online",
          "tokens_per_second": 137.0,
          "ttft": 0.616,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 16.77,
          "status": "Online",
          "tokens_per_second": 60.0,
          "ttft": 0.698,
          "streaming_smoothness": 0.456
        },
        "OpenAI": {
          "time": 19.25,
          "status": "Online",
          "tokens_per_second": 72.0,
          "ttft": 1.263,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.74,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 1.383,
          "streaming_smoothness": 0.116
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-14 12:55:05 UTC",
      "results": {
        "Groq": {
          "time": 1.74,
          "status": "Online",
          "tokens_per_second": 390.0,
          "ttft": 0.212,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.98,
          "status": "Online",
          "tokens_per_second": 195.0,
          "ttft": 0.214,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.2,
          "status": "Online",
          "tokens_per_second": 52.0,
          "ttft": 0.451,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.05,
          "status": "Online",
          "tokens_per_second": 61.0,
          "ttft": 1.469,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.87,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.213,
          "streaming_smoothness": 0.026
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    }
  ],
  "reliability_scores": {
    "Groq": 100.0,
    "Together AI": 100.0,
    "OpenAI": 100.0,
    "Mistral AI": 100.0,
    "DeepSeek": 100.0,
    "Anthropic": 0.0,
    "Google": 0.0,
    "Cohere": 0.0,
    "Fireworks": 0.0,
    "Cerebras": 0.0
  },
  "metadata": {
    "version": "3.0",
    "parallel_testing": false,
    "streaming_enabled": true,
    "timeout": 90,
    "retries": 3
  }
}