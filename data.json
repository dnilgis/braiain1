{
  "last_updated": "2025-12-14 02:25:59 UTC",
  "prompt": "You are tasked with analyzing the evolution of artificial intelligence from 2010 to 2025. Your response must be comprehensive and well-structured.\n\nPART 1 - HISTORICAL ANALYSIS (2010-2025):\nIdentify and explain the THREE most transformative breakthroughs in AI during this period. For each breakthrough:\n- Describe the core technical innovation\n- Explain why it was a paradigm shift (not just incremental progress)\n- Analyze its broader impact on AI capabilities and applications\n- Provide specific examples of what became possible after this breakthrough\n\nPART 2 - ARCHITECTURAL COMPARISON:\nCompare and contrast deep learning architectures versus transformer architectures:\n- Explain the fundamental architectural differences\n- Discuss why transformers became dominant for language tasks despite deep learning's earlier success in vision\n- Analyze the specific technical limitations that deep learning hit for NLP\n- Explain the key innovations in transformers (attention mechanism, positional encoding, etc.) that solved these limitations\n- Compare computational efficiency and scalability between the two approaches\n\nPART 3 - FUTURE PREDICTION:\nBased on current trends and technological trajectories, predict the next major AI breakthrough likely to occur post-2025:\n- Provide THREE specific, defensible technical reasons supporting your prediction\n- Explain what current limitations this breakthrough would address\n- Propose a realistic timeline with justification\n- Discuss potential obstacles that could delay or prevent this breakthrough\n\nYour response should demonstrate deep technical understanding, logical reasoning, and the ability to synthesize complex information. Aim for 2500-3500 characters with clear structure and specific technical details.",
  "max_tokens": 1000,
  "results": [
    {
      "provider": "Groq",
      "model": "llama-3.3-70b-versatile",
      "status": "Online",
      "time": 1.42,
      "ttft": 0.159,
      "tokens_per_second": 385.0,
      "streaming_smoothness": 0,
      "output_tokens": 547,
      "character_count": 2191,
      "cost_per_request": 0.0,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1. **Deep Learning (2010)**: Core technical innovation - neural networks with multiple layers. Paradigm shift - enabled learning of complex patterns. Broader impact - improved image recognition, speech recognition, and natural language processing. Examples - self-driving cars, voice assistants.\n\n2. **Transformer Architecture (2017)**: Core technical innovation - self-attention mechanism. Paradigm shift - replaced recurrent neural networks for sequence-to-sequence tasks. Broader impact - improved machine translation, text generation, and question answering. Examples - language models like BERT and RoBERTa.\n\n3. **Generative Adversarial Networks (GANs) (2014)**: Core technical innovation - simultaneous training of generator and discriminator networks. Paradigm shift - enabled generation of realistic synthetic data. Broader impact - improved data augmentation, style transfer, and data anonymization. Examples - generating realistic images and videos.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\nDeep learning architectures rely on convolutional and recurrent neural networks, whereas transformer architectures utilize self-attention mechanisms. Transformers became dominant for language tasks due to their ability to model long-range dependencies and parallelize sequence processing. Deep learning hit limitations in NLP due to the sequential nature of RNNs, which transformers addressed with attention mechanisms and positional encoding. Transformers are more computationally efficient and scalable than deep learning approaches for sequence-to-sequence tasks.\n\n**PART 3 - FUTURE PREDICTION**\n\nNext major AI breakthrough - **Explainable AI (XAI)**. Technical reasons: (1) increasing demand for transparent decision-making, (2) development of techniques like saliency maps and feature importance, and (3) integration of cognitive architectures with deep learning. Current limitations - lack of interpretability in complex models. Realistic timeline - 2028-2030, with ongoing research in XAI and cognitive architectures. Potential obstacles - balancing interpretability with performance, addressing the complexity of real-world applications.",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1. **Deep Learning (2010)**: Core technical innovation - neural networks with multiple layers. Paradigm shift - enabled learning of complex patterns. Broa...",
      "error_info": null
    },
    {
      "provider": "Together AI",
      "model": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
      "status": "Online",
      "time": 7.33,
      "ttft": 0.35,
      "tokens_per_second": 169.0,
      "streaming_smoothness": 0,
      "output_tokens": 1238,
      "character_count": 4953,
      "cost_per_request": 0.00148,
      "full_response": "**Part 1: Historical Analysis (2010-2025)**\n\n1. **AlexNet (2012)**: Core technical innovation - Deep Learning (Convolutional Neural Networks, CNNs)\nParadigm shift: Demonstrated that deep neural networks can be trained effectively, achieving state-of-the-art results in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC).\nImpact: Revitalized interest in deep learning, enabling breakthroughs in computer vision (image classification, object detection, segmentation) and its applications in various industries (self-driving cars, medical imaging, etc.).\nExample: AlexNet's success led to the development of more complex models like VGGNet and ResNet, enabling applications like facial recognition and object detection in images and videos.\n\n2. **Sequence-to-Sequence Models (2014)**: Core technical innovation - Encoder-Decoder Architecture with Recurrent Neural Networks (RNNs)\nParadigm shift: Introduced a novel architecture for machine translation, enabling the development of more sophisticated language models.\nImpact: Transformed natural language processing (NLP) capabilities, enabling tasks like machine translation, text summarization, and chatbots.\nExample: Google's Neural Machine Translation (GNMT) system, built on sequence-to-sequence models, achieved state-of-the-art results in machine translation, showcasing the potential of deep learning in NLP.\n\n3. **Transformers (2017)**: Core technical innovation - Self-Attention Mechanism with Positional Encoding\nParadigm shift: Revolutionized NLP by introducing a non-recurrent architecture that scales better and captures longer-range dependencies in sequential data.\nImpact: Led to significant improvements in NLP tasks, such as language modeling, text generation, and sentiment analysis, while facilitating the development of BERT and other pre-trained language models.\nExample: Transformer-based models like BERT and RoBERTa achieved state-of-the-art results in various NLP tasks, including question answering, sentiment analysis, and text classification.\n\n**Part 2: Architectural Comparison**\n\n**Deep Learning Architectures vs. Transformer Architectures**\n\nDeep Learning Architectures:\n- Fundamental architecture: Convolutional and Recurrent Neural Networks (CNNs and RNNs)\n- Earlier success: Primarily in computer vision tasks like image classification and object detection\n\nTransformer Architectures:\n- Fundamental architecture: Self-Attention Mechanism with Positional Encoding\n- Dominant in NLP: Revolutionized language tasks like machine translation, text generation, and question answering\n\n**Why Transformers Dominated NLP:**\n\n- **Technical limitations of deep learning in NLP**: Deep learning architectures struggled to capture long-range dependencies in sequential data, leading to issues with parallelization and scalability.\n- **Key innovations in transformers**:\n  - **Self-Attention Mechanism**: Enables the model to focus on different parts of the input data when computing the representation of another part.\n  - **Positional Encoding**: Provides a way to inject positional information into the input data, enabling the model to capture long-range dependencies.\n\n**Computational Efficiency and Scalability:**\n\n- Deep Learning Architectures: Generally more computationally expensive and challenging to parallelize due to recurrent structure.\n- Transformer Architectures: More efficient and scalable, thanks to parallelizable self-attention mechanism and lack of recurrence.\n\n**Part 3: Future Prediction**\n\n**Breakthrough Prediction:**\n\n- Multimodal Learning with Multitask Meta-Learning (MT-MTL)\n- **Reason 1:** MT-MTL can effectively combine multiple sources of information, enabling the development of more generalizable and robust AI models.\n- **Reason 2:** By leveraging multitask meta-learning, MT-MTL can adapt to new tasks and domains more efficiently, reducing the need for extensive retraining and fine-tuning.\n- **Reason 3:** MT-MTL can integrate insights from cognitive science and neuroscience to develop more human-like learning mechanisms, enabling AI systems to learn more efficiently and effectively.\n\n**Timeline Prediction:** 2027-2032\n\n**Justification:** Current progress in multitask meta-learning and multimodal learning, combined with growing interest in developing more generalizable and human-like AI systems, suggests that MT-MTL is a promising area for the next major AI breakthrough.\n\n**Potential Obstacles:**\n\n- **Complexity of multimodal datasets**: MT-MTL requires access to large, diverse multimodal datasets, which can be challenging to create and curate.\n- **Need for advanced meta-learning algorithms**: Developing efficient and effective multitask meta-learning algorithms is a non-trivial task, requiring significant advances in areas like few-shot learning and transfer learning.\n- **Lack of clear evaluation metrics**: Developing robust evaluation metrics for MT-MTL systems can be challenging, hindering progress in the field.",
      "response_preview": "**Part 1: Historical Analysis (2010-2025)**\n\n1. **AlexNet (2012)**: Core technical innovation - Deep Learning (Convolutional Neural Networks, CNNs)\nParadigm shift: Demonstrated that deep neural networ...",
      "error_info": null
    },
    {
      "provider": "Mistral AI",
      "model": "mistral-large-latest",
      "status": "Online",
      "time": 19.12,
      "ttft": 0.455,
      "tokens_per_second": 52.0,
      "streaming_smoothness": 0,
      "output_tokens": 995,
      "character_count": 3981,
      "cost_per_request": 0.00685,
      "full_response": "# **The Evolution of Artificial Intelligence (2010\u20132025): A Comprehensive Analysis**\n\n## **PART 1 \u2013 HISTORICAL ANALYSIS (2010\u20132025): Three Transformative Breakthroughs**\n\n### **1. Deep Learning Resurgence (2012\u20132015): The Neural Network Renaissance**\n#### **Core Technical Innovation**\nThe revival of deep learning was catalyzed by **AlexNet (2012)**, a convolutional neural network (CNN) that achieved a **10.8% error rate** in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), nearly halving the previous best (26.2%). Key innovations included:\n- **GPU acceleration** (NVIDIA CUDA) for training deep networks.\n- **ReLU (Rectified Linear Unit) activation functions**, replacing sigmoid/tanh, mitigating the vanishing gradient problem.\n- **Dropout regularization** to prevent overfitting.\n- **Data augmentation** to artificially expand training datasets.\n\n#### **Paradigm Shift**\nBefore 2012, machine learning relied on **handcrafted features** (e.g., SIFT, HOG) and shallow models (SVMs, random forests). Deep learning **automated feature extraction**, eliminating the need for domain expertise. This marked a shift from **\"feature engineering\"** to **\"representation learning\"**, where models learned hierarchical abstractions directly from raw data.\n\n#### **Broader Impact**\n- **Computer Vision:** Enabled real-time object detection (YOLO, 2015), facial recognition (DeepFace, 2014), and medical imaging (e.g., tumor detection in MRIs).\n- **Speech Recognition:** Microsoft\u2019s 2016 speech recognition system achieved **human parity** (5.9% error rate) using deep neural networks (DNNs).\n- **Autonomous Systems:** Tesla\u2019s Autopilot (2014) and Waymo\u2019s self-driving cars leveraged CNNs for perception.\n\n#### **What Became Possible?**\n- **Real-time video analysis** (e.g., surveillance, sports analytics).\n- **End-to-end learning** (e.g., AlphaGo, 2016, which combined CNNs with reinforcement learning).\n- **Transfer learning**, where pre-trained models (e.g., ResNet, VGG) were fine-tuned for new tasks with minimal data.\n\n---\n\n### **2. Transformer Architecture (2017\u20132020): The Attention Revolution**\n#### **Core Technical Innovation**\nThe **Transformer** (Vaswani et al., 2017) introduced:\n- **Self-attention mechanism**, allowing models to weigh the importance of different input tokens dynamically.\n- **Positional encoding**, enabling sequence processing without recurrence (unlike RNNs/LSTMs).\n- **Parallelization**, drastically reducing training time compared to sequential RNNs.\n\n#### **Paradigm Shift**\nBefore Transformers, **recurrent neural networks (RNNs)** and **long short-term memory (LSTM)** networks dominated NLP. However, they suffered from:\n- **Vanishing gradients** in long sequences.\n- **Sequential processing**, making parallelization impossible.\n- **Fixed-length context windows**, limiting long-range dependencies.\n\nTransformers **eliminated recurrence entirely**, replacing it with **attention**, which computes relationships between all tokens in parallel. This enabled **scalable, context-aware language models**.\n\n#### **Broader Impact**\n- **Natural Language Processing (NLP):**\n  - **BERT (2018)** achieved state-of-the-art results in 11 NLP tasks by pre-training on massive text corpora.\n  - **GPT-3 (2020)** demonstrated **few-shot learning**, generating human-like text with minimal prompts.\n- **Multimodal AI:** Models like **DALL\u00b7E (2021)** and **CLIP (2021)** combined vision and language via Transformers.\n- **Efficiency Gains:** Training time for large models dropped from months (LSTMs) to days (Transformers).\n\n#### **What Became Possible?**\n- **Conversational AI** (e.g., ChatGPT, 2022).\n- **Code generation** (e.g., GitHub Copilot, 2021).\n- **Zero-shot and few-shot learning**, reducing data requirements.\n\n---\n\n### **3. Scalable Foundation Models & Reinforcement Learning from Human Feedback (RLHF) (2020\u20132025)**\n#### **Core Technical Innovation**\n- **Foundation Models (2020\u20132022):** Large-scale pre-trained models (e.g., GPT-",
      "response_preview": "# **The Evolution of Artificial Intelligence (2010\u20132025): A Comprehensive Analysis**\n\n## **PART 1 \u2013 HISTORICAL ANALYSIS (2010\u20132025): Three Transformative Breakthroughs**\n\n### **1. Deep Learning Resurg...",
      "error_info": null
    },
    {
      "provider": "OpenAI",
      "model": "gpt-4o-mini",
      "status": "Online",
      "time": 23.38,
      "ttft": 1.13,
      "tokens_per_second": 59.0,
      "streaming_smoothness": 0,
      "output_tokens": 1385,
      "character_count": 5540,
      "cost_per_request": 0.0009,
      "full_response": "### PART 1 - HISTORICAL ANALYSIS (2010-2025)\n\n#### Breakthrough 1: Deep Learning Revolution (2012)\n\n**Core Technical Innovation:** \nThe introduction of convolutional neural networks (CNNs) significantly improved the state of visual recognition tasks. Notably, AlexNet, which won the ImageNet competition in 2012, utilized deep learning techniques to dramatically reduce error rates in image classification.\n\n**Paradigm Shift:**\nBefore 2012, traditional machine learning methods predicated on handcrafted features were the norm for visual recognition. The success of deep learning marked a fundamental shift, enabling the model to automatically learn features from raw data, thereby reducing human intervention and error in feature selection.\n\n**Broader Impact:**\nThis reshaped not only computer vision but also catalyzed advancements in other domains like speech recognition and natural language processing (NLP). New tools and libraries, such as TensorFlow and PyTorch, emerged, making deep learning accessible to a broader audience.\n\n**Examples:**\nAfter 2012, applications such as real-time image recognition (e.g., facial recognition in security), autonomous driving technologies (e.g., vehicle detection), and medical imaging analysis became feasible and standard.\n\n---\n\n#### Breakthrough 2: Generative Adversarial Networks (GANs) (2014)\n\n**Core Technical Innovation:**\nIan Goodfellow's introduction of GANs employs two neural networks\u2014the generator and discriminator\u2014that compete against each other, fostering a unique method for generating new data from learned distributions.\n\n**Paradigm Shift:**\nGANs weren't simply an improvement on generative models; they enabled the creation of high-quality synthetic data that had never been seen before. This altered the approach to creativity and content generation in AI.\n\n**Broader Impact:**\nGANs opened avenues in art, fashion, and content creation, providing powerful tools for media designers and artists that allowed them to produce unique works and augmented reality experiences.\n\n**Examples:**\nPost-GANs, applications like deepfake technology, improved image super-resolution, and the generation of entirely new artworks became apparent, raising ethical debates in the process.\n\n---\n\n#### Breakthrough 3: Transformer Architecture (2017)\n\n**Core Technical Innovation:**\nThe transformer model introduced attention mechanisms that allow the model to weigh the significance of different input parts independently, rather than processing inputs sequentially like RNNs.\n\n**Paradigm Shift:**\nTransformers enabled models to capture long-range dependencies without the limitations of sequence length, which complemented the need for parallelization in training, thus accelerating the learning process considerably.\n\n**Broader Impact:**\nThis innovation laid the groundwork for large-scale pre-trained models, revolutionizing NLP and setting the stage for advancements in multi-modal learning.\n\n**Examples:**\nPost-transformer, models like BERT and GPT-3 facilitated unprecedented capabilities in language understanding and generation, resulting in applications like advanced chatbots, translation services, and content creation tools.\n\n---\n\n### PART 2 - ARCHITECTURAL COMPARISON\n\n**Fundamental Architectural Differences:**\nDeep learning architectures, particularly convolutions and recurrent neural networks (RNNs), excelled in static inputs or sequential data processing respectively. In contrast, transformers entirely rely on self-attention mechanisms without recurrence or convolutions, capturing context globally rather than locally.\n\n**Dominance in Language Tasks:**\nTransformers became dominant in NLP due to their ability to process entire sequences simultaneously (parallelization), addressing the inefficiencies of RNNs, which regressed with longer sequences due to vanishing gradient issues during both training and inference.\n\n**Limitations of Deep Learning in NLP:**\nTraditional deep learning faced challenges in managing contextual understanding across lengthy sequences, often losing relevance or meaning further down the line. Models like LSTMs struggled with sequence lengths that exceeded their memory capacity.\n\n**Key Innovations in Transformers:**\nThe attention mechanism allows the model to focus dynamically on different input words to discern context while positional encoding addresses the sequential nature of text by injecting information about the order of tokens.\n\n**Computational Efficiency and Scalability:**\nWhile deep learning models scale poorly with larger datasets and require sequential computations, transformers leverage parallel processing, enabling much larger datasets to be utilized effectively, thus improving scalability and efficiency.\n\n---\n\n### PART 3 - FUTURE PREDICTION\n\n**Predicted Breakthrough: Neuromorphic Computing**\n\n**Technical Reasons:**\n1. **Energy Efficiency:** Neuromorphic chips, designed to mimic human neuronal structures, could dramatically lower energy consumption, a significant bottleneck in large-scale AI applications today.\n2. **Real-time Processing:** Such architectures promise real-time processing capabilities akin to human cognition, facilitating AI on edge devices for applications like robotics and IoT.\n3. **Adaptive Learning:** Neuromorphic computing can bring about true continuous learning systems that adapt to new data in their environment without explicit retraining.\n\n**Current Limitations Addressed:**\nCurrently, AI systems struggle with energy consumption, adaptiveness to dynamic environments, and even basic",
      "response_preview": "### PART 1 - HISTORICAL ANALYSIS (2010-2025)\n\n#### Breakthrough 1: Deep Learning Revolution (2012)\n\n**Core Technical Innovation:** \nThe introduction of convolutional neural networks (CNNs) significant...",
      "error_info": null
    },
    {
      "provider": "DeepSeek",
      "model": "deepseek-chat",
      "status": "Online",
      "time": 35.4,
      "ttft": 1.169,
      "tokens_per_second": 35.0,
      "streaming_smoothness": 0.08,
      "output_tokens": 1235,
      "character_count": 4942,
      "cost_per_request": 0.00041,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1.  **Deep Learning Revolution (c. 2012):**\n    *   **Core Innovation:** The effective training of very deep convolutional neural networks (CNNs) using GPUs, backpropagation, and techniques like ReLU and Dropout.\n    *   **Paradigm Shift:** Moved AI from hand-engineered feature extraction to end-to-end learned hierarchical representations directly from raw data.\n    *   **Impact & Example:** Enabled superhuman performance on image classification (AlexNet on ImageNet). This breakthrough made perception (vision, speech) a solved problem for many commercial applications, enabling facial recognition, real-time translation, and autonomous vehicle perception.\n\n2.  **Transformer Architecture (2017):**\n    *   **Core Innovation:** The \"attention is all you need\" mechanism, discarding recurrence and convolution for self-attention and positional encoding.\n    *   **Paradigm Shift:** Replaced sequential processing with parallelizable, context-aware processing of entire sequences, fundamentally changing NLP.\n    *   **Impact & Example:** Allowed training on previously impossible scales of data and model size. Directly led to the GPT series and BERT, enabling few-shot learning, coherent long-form text generation, and foundation models that could be fine-tuned for diverse tasks.\n\n3.  **Scale and the Emergence of Foundation Models (2020-2023):**\n    *   **Core Innovation:** The empirical discovery that predictably scaling compute, data, and model parameters (scaling laws) led to emergent abilities like reasoning and in-context learning in large language models (LLMs).\n    *   **Paradigm Shift:** Moved from training narrow AI models to pre-training a single, massively scalable \"base\" model that could be adapted to thousands of downstream tasks via prompting or lightweight fine-tuning.\n    *   **Impact & Example:** Enabled general-purpose AI assistants (ChatGPT, Copilot), multimodality (CLIP, DALL-E), and the shift from model-centric to data- and infrastructure-centric AI development.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\n*   **Fundamental Differences:** Deep learning (specifically CNNs/RNNs) relies on **inductive biases** tailored to data structure: local connectivity and translation invariance (CNNs) for images, sequential processing (RNNs) for text. Transformers use **self-attention**, which dynamically weights the importance of all elements in a sequence, regardless of distance, with minimal built-in structural bias.\n*   **Dominance in NLP:** CNNs excelled in vision due to their spatial hierarchy bias, a natural fit for images. RNNs, the prior NLP standard, were fundamentally limited by sequential processing (slow, poor long-range dependency handling due to vanishing gradients). Transformers solved this via parallelizable self-attention, enabling efficient training on massive text corpora and capturing long-range context perfectly.\n*   **Transformer Innovations:**\n    *   **Self-Attention:** Computes relationships between all tokens simultaneously, solving the long-range dependency problem.\n    *   **Positional Encoding:** Injects sequence order information since attention alone is permutation-invariant.\n    *   **Layer Normalization & Residual Connections:** Enabled stable training of very deep networks.\n*   **Efficiency & Scalability:** For sequence tasks, transformers are far more computationally efficient *during training* due to parallelization. However, their self-attention mechanism scales quadratically with sequence length, a key limitation versus CNNs' linear scaling. Transformers' scalability in model size (parameters) is what unlocked the era of LLMs.\n\n**PART 3 - FUTURE PREDICTION**\n\n**Prediction:** The next major breakthrough will be the widespread adoption of **highly sample-efficient, reasoning-focused architectures** that integrate neural networks with formal, algorithmic modules (e.g., Neuro-Symbolic AI or LLM-based \"System 2\" models).\n\n**Three Supporting Reasons:**\n1.  **Limitation of Autoregressive Next-Token Prediction:** Current LLMs lack robust, verifiable reasoning and struggle with planning, precise deduction, and dynamic knowledge updates.\n2.  **Economic Imperative:** The cost of scaling pure data-driven models is becoming prohibitive; breakthroughs in sample efficiency are necessary.\n3.  **Research Trajectory:** Strong currents in AI research are focused on LLM verification, tool use, and prompting strategies (e.g., Chain-of-Thought, Tree of Thoughts) that explicitly separate \"thinking\" from \"answering.\"\n\n**Limitations Addressed:** This would address hallucinations, poor logical consistency, and the massive computational/data footprint of current models, enabling reliable deployment in science, engineering, and mission-critical systems.\n\n**Realistic Timeline:** Initial research frameworks will show compelling results by 2027, with the first stable commercial architectures emerging around 203",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1.  **Deep Learning Revolution (c. 2012):**\n    *   **Core Innovation:** The effective training of very deep convolutional neural networks (CNNs) using GP...",
      "error_info": null
    },
    {
      "provider": "Anthropic",
      "model": "claude-3-5-sonnet-20241022",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-14 02:24:21 UTC"
      }
    },
    {
      "provider": "Google",
      "model": "gemini-1.5-flash",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-14 02:24:28 UTC"
      }
    },
    {
      "provider": "Cohere",
      "model": "command-r-plus",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-14 02:24:58 UTC"
      }
    },
    {
      "provider": "Fireworks",
      "model": "accounts/fireworks/models/llama-v3p1-70b-instruct",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-14 02:25:51 UTC"
      }
    },
    {
      "provider": "Cerebras",
      "model": "llama3.1-70b",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-14 02:25:58 UTC"
      }
    }
  ],
  "history": [
    {
      "timestamp": "2025-12-06 18:37:29 UTC",
      "results": {
        "Groq": {
          "time": 1.73,
          "status": "Online",
          "tokens_per_second": 328.0,
          "ttft": 0.269,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.3,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.321,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.75,
          "status": "Online",
          "tokens_per_second": 47.0,
          "ttft": 0.937,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.53,
          "status": "Online",
          "tokens_per_second": 60.0,
          "ttft": 1.129,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 30.91,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 1.358,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 02:25:22 UTC",
      "results": {
        "Groq": {
          "time": 1.68,
          "status": "Online",
          "tokens_per_second": 320.0,
          "ttft": 0.199,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.37,
          "status": "Online",
          "tokens_per_second": 115.0,
          "ttft": 0.685,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.59,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.738,
          "streaming_smoothness": 0.192
        },
        "OpenAI": {
          "time": 20.78,
          "status": "Online",
          "tokens_per_second": 65.0,
          "ttft": 1.14,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 36.26,
          "status": "Online",
          "tokens_per_second": 34.0,
          "ttft": 1.497,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 06:39:23 UTC",
      "results": {
        "Groq": {
          "time": 1.54,
          "status": "Online",
          "tokens_per_second": 336.0,
          "ttft": 0.197,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.86,
          "status": "Online",
          "tokens_per_second": 144.0,
          "ttft": 0.436,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 16.83,
          "status": "Online",
          "tokens_per_second": 80.0,
          "ttft": 1.303,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.56,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 1.576,
          "streaming_smoothness": 0.067
        },
        "DeepSeek": {
          "time": 34.65,
          "status": "Online",
          "tokens_per_second": 36.0,
          "ttft": 1.226,
          "streaming_smoothness": 0.065
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 12:52:59 UTC",
      "results": {
        "Groq": {
          "time": 1.45,
          "status": "Online",
          "tokens_per_second": 350.0,
          "ttft": 0.143,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.81,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.291,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.96,
          "status": "Online",
          "tokens_per_second": 49.0,
          "ttft": 0.471,
          "streaming_smoothness": 0.799
        },
        "OpenAI": {
          "time": 22.43,
          "status": "Online",
          "tokens_per_second": 61.0,
          "ttft": 1.374,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.79,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.366,
          "streaming_smoothness": 0.042
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 18:37:46 UTC",
      "results": {
        "Groq": {
          "time": 1.38,
          "status": "Online",
          "tokens_per_second": 396.0,
          "ttft": 0.158,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 11.08,
          "status": "Online",
          "tokens_per_second": 117.0,
          "ttft": 0.98,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.22,
          "status": "Online",
          "tokens_per_second": 69.0,
          "ttft": 1.189,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.5,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 3.31,
          "streaming_smoothness": 0.241
        },
        "DeepSeek": {
          "time": 33.12,
          "status": "Online",
          "tokens_per_second": 38.0,
          "ttft": 3.082,
          "streaming_smoothness": 0.023
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 02:11:03 UTC",
      "results": {
        "Groq": {
          "time": 1.8,
          "status": "Online",
          "tokens_per_second": 375.0,
          "ttft": 0.266,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.83,
          "status": "Online",
          "tokens_per_second": 173.0,
          "ttft": 0.271,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.47,
          "status": "Online",
          "tokens_per_second": 65.0,
          "ttft": 1.042,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.16,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 3.077,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.87,
          "status": "Online",
          "tokens_per_second": 31.0,
          "ttft": 1.378,
          "streaming_smoothness": 0.09
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 06:48:36 UTC",
      "results": {
        "Groq": {
          "time": 1.74,
          "status": "Online",
          "tokens_per_second": 377.0,
          "ttft": 0.225,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 13.09,
          "status": "Online",
          "tokens_per_second": 92.0,
          "ttft": 0.437,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.19,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.137,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.39,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 2.397,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.6,
          "status": "Online",
          "tokens_per_second": 30.0,
          "ttft": 1.27,
          "streaming_smoothness": 0.033
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 13:00:14 UTC",
      "results": {
        "Groq": {
          "time": 2.12,
          "status": "Online",
          "tokens_per_second": 347.0,
          "ttft": 0.276,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.36,
          "status": "Online",
          "tokens_per_second": 127.0,
          "ttft": 0.471,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.23,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 1.478,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 24.11,
          "status": "Online",
          "tokens_per_second": 41.0,
          "ttft": 0.711,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.71,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.107,
          "streaming_smoothness": 0.084
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 18:43:36 UTC",
      "results": {
        "Groq": {
          "time": 1.88,
          "status": "Online",
          "tokens_per_second": 350.0,
          "ttft": 0.271,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.49,
          "status": "Online",
          "tokens_per_second": 195.0,
          "ttft": 0.364,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.68,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 1.341,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.7,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 1.074,
          "streaming_smoothness": 0.47
        },
        "DeepSeek": {
          "time": 32.09,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 0.935,
          "streaming_smoothness": 0.071
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 02:09:54 UTC",
      "results": {
        "Groq": {
          "time": 1.97,
          "status": "Online",
          "tokens_per_second": 416.0,
          "ttft": 0.198,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.4,
          "status": "Online",
          "tokens_per_second": 143.0,
          "ttft": 0.309,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.03,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 2.049,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.46,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.665,
          "streaming_smoothness": 0.51
        },
        "DeepSeek": {
          "time": 38.93,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.506,
          "streaming_smoothness": 0.021
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 06:45:12 UTC",
      "results": {
        "Groq": {
          "time": 1.66,
          "status": "Online",
          "tokens_per_second": 334.0,
          "ttft": 0.258,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.28,
          "status": "Online",
          "tokens_per_second": 157.0,
          "ttft": 0.446,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.87,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 1.486,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 32.11,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 1.192,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 42.03,
          "status": "Online",
          "tokens_per_second": 29.0,
          "ttft": 2.249,
          "streaming_smoothness": 0.061
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 13:02:20 UTC",
      "results": {
        "Groq": {
          "time": 1.69,
          "status": "Online",
          "tokens_per_second": 388.0,
          "ttft": 0.153,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.25,
          "status": "Online",
          "tokens_per_second": 190.0,
          "ttft": 0.35,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.22,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.225,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 26.15,
          "status": "Online",
          "tokens_per_second": 37.0,
          "ttft": 3.278,
          "streaming_smoothness": 0.494
        },
        "DeepSeek": {
          "time": 38.27,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.353,
          "streaming_smoothness": 0.037
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 18:39:45 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 365.0,
          "ttft": 0.168,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.55,
          "status": "Online",
          "tokens_per_second": 151.0,
          "ttft": 0.651,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 23.07,
          "status": "Online",
          "tokens_per_second": 64.0,
          "ttft": 1.297,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 26.09,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 1.506,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 31.69,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.187,
          "streaming_smoothness": 0.077
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 02:11:51 UTC",
      "results": {
        "Groq": {
          "time": 1.75,
          "status": "Online",
          "tokens_per_second": 403.0,
          "ttft": 0.366,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.22,
          "status": "Online",
          "tokens_per_second": 207.0,
          "ttft": 0.582,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.95,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 2.078,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 25.37,
          "status": "Online",
          "tokens_per_second": 55.0,
          "ttft": 1.827,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.45,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.231,
          "streaming_smoothness": 0.093
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 06:45:39 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 376.0,
          "ttft": 0.189,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.16,
          "status": "Online",
          "tokens_per_second": 146.0,
          "ttft": 0.333,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.43,
          "status": "Online",
          "tokens_per_second": 50.0,
          "ttft": 1.996,
          "streaming_smoothness": 0.299
        },
        "OpenAI": {
          "time": 26.86,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.981,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.07,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.192,
          "streaming_smoothness": 0.027
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 13:02:42 UTC",
      "results": {
        "Groq": {
          "time": 1.36,
          "status": "Online",
          "tokens_per_second": 325.0,
          "ttft": 0.205,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.29,
          "status": "Online",
          "tokens_per_second": 147.0,
          "ttft": 0.31,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.6,
          "status": "Online",
          "tokens_per_second": 42.0,
          "ttft": 1.082,
          "streaming_smoothness": 0.488
        },
        "OpenAI": {
          "time": 24.1,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 1.467,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.88,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.121,
          "streaming_smoothness": 0.109
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 18:42:03 UTC",
      "results": {
        "Groq": {
          "time": 1.7,
          "status": "Online",
          "tokens_per_second": 379.0,
          "ttft": 0.269,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.25,
          "status": "Online",
          "tokens_per_second": 178.0,
          "ttft": 0.217,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.84,
          "status": "Online",
          "tokens_per_second": 60.0,
          "ttft": 1.331,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.92,
          "status": "Online",
          "tokens_per_second": 48.0,
          "ttft": 0.509,
          "streaming_smoothness": 0.258
        },
        "DeepSeek": {
          "time": 31.5,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.568,
          "streaming_smoothness": 0.1
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 02:13:30 UTC",
      "results": {
        "Groq": {
          "time": 1.5,
          "status": "Online",
          "tokens_per_second": 380.0,
          "ttft": 0.201,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.78,
          "status": "Online",
          "tokens_per_second": 146.0,
          "ttft": 0.258,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 18.95,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 1.227,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.36,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 0.479,
          "streaming_smoothness": 0.496
        },
        "DeepSeek": {
          "time": 39.35,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.931,
          "streaming_smoothness": 0.099
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 06:47:15 UTC",
      "results": {
        "Groq": {
          "time": 1.54,
          "status": "Online",
          "tokens_per_second": 356.0,
          "ttft": 0.257,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.7,
          "status": "Online",
          "tokens_per_second": 206.0,
          "ttft": 0.307,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.5,
          "status": "Online",
          "tokens_per_second": 42.0,
          "ttft": 0.509,
          "streaming_smoothness": 0.525
        },
        "OpenAI": {
          "time": 24.47,
          "status": "Online",
          "tokens_per_second": 58.0,
          "ttft": 0.985,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.04,
          "status": "Online",
          "tokens_per_second": 31.0,
          "ttft": 1.5,
          "streaming_smoothness": 0.113
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 13:03:57 UTC",
      "results": {
        "Groq": {
          "time": 1.6,
          "status": "Online",
          "tokens_per_second": 332.0,
          "ttft": 0.298,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.11,
          "status": "Online",
          "tokens_per_second": 152.0,
          "ttft": 0.53,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.29,
          "status": "Online",
          "tokens_per_second": 53.0,
          "ttft": 0.741,
          "streaming_smoothness": 0.691
        },
        "OpenAI": {
          "time": 22.25,
          "status": "Online",
          "tokens_per_second": 62.0,
          "ttft": 1.406,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.62,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.423,
          "streaming_smoothness": 0.093
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 18:42:55 UTC",
      "results": {
        "Groq": {
          "time": 1.35,
          "status": "Online",
          "tokens_per_second": 370.0,
          "ttft": 0.196,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 14.46,
          "status": "Online",
          "tokens_per_second": 91.0,
          "ttft": 0.482,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.23,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.489,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.77,
          "status": "Online",
          "tokens_per_second": 69.0,
          "ttft": 1.935,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 32.35,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.178,
          "streaming_smoothness": 0.006
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 02:13:32 UTC",
      "results": {
        "Groq": {
          "time": 1.67,
          "status": "Online",
          "tokens_per_second": 343.0,
          "ttft": 0.193,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.98,
          "status": "Online",
          "tokens_per_second": 113.0,
          "ttft": 0.698,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.82,
          "status": "Online",
          "tokens_per_second": 56.0,
          "ttft": 0.733,
          "streaming_smoothness": 0.107
        },
        "OpenAI": {
          "time": 20.16,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.33,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.35,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.392,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 06:45:53 UTC",
      "results": {
        "Groq": {
          "time": 1.83,
          "status": "Online",
          "tokens_per_second": 452.0,
          "ttft": 0.205,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.83,
          "status": "Online",
          "tokens_per_second": 162.0,
          "ttft": 0.603,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.15,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.673,
          "streaming_smoothness": 0.26
        },
        "OpenAI": {
          "time": 27.03,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 1.562,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.38,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.421,
          "streaming_smoothness": 0.045
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 13:00:50 UTC",
      "results": {
        "Groq": {
          "time": 1.77,
          "status": "Online",
          "tokens_per_second": 423.0,
          "ttft": 0.186,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.7,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.41,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.84,
          "status": "Online",
          "tokens_per_second": 64.0,
          "ttft": 1.433,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 24.34,
          "status": "Online",
          "tokens_per_second": 38.0,
          "ttft": 0.747,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 37.37,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.349,
          "streaming_smoothness": 0.121
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 18:42:55 UTC",
      "results": {
        "Groq": {
          "time": 1.64,
          "status": "Online",
          "tokens_per_second": 363.0,
          "ttft": 0.129,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.92,
          "status": "Online",
          "tokens_per_second": 148.0,
          "ttft": 0.468,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.48,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 0.49,
          "streaming_smoothness": 0.041
        },
        "OpenAI": {
          "time": 23.98,
          "status": "Online",
          "tokens_per_second": 58.0,
          "ttft": 1.461,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 31.27,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 1.173,
          "streaming_smoothness": 0.096
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 02:06:27 UTC",
      "results": {
        "Groq": {
          "time": 1.81,
          "status": "Online",
          "tokens_per_second": 352.0,
          "ttft": 0.28,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 13.11,
          "status": "Online",
          "tokens_per_second": 136.0,
          "ttft": 0.466,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.85,
          "status": "Online",
          "tokens_per_second": 53.0,
          "ttft": 0.757,
          "streaming_smoothness": 0.299
        },
        "OpenAI": {
          "time": 26.05,
          "status": "Online",
          "tokens_per_second": 52.0,
          "ttft": 1.229,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 36.91,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 1.277,
          "streaming_smoothness": 0.017
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 06:41:23 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 340.0,
          "ttft": 0.155,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.27,
          "status": "Online",
          "tokens_per_second": 148.0,
          "ttft": 0.304,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.18,
          "status": "Online",
          "tokens_per_second": 59.0,
          "ttft": 0.444,
          "streaming_smoothness": 0.303
        },
        "OpenAI": {
          "time": 20.83,
          "status": "Online",
          "tokens_per_second": 66.0,
          "ttft": 1.398,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.67,
          "status": "Online",
          "tokens_per_second": 36.0,
          "ttft": 1.269,
          "streaming_smoothness": 0.002
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 12:55:08 UTC",
      "results": {
        "Groq": {
          "time": 1.9,
          "status": "Online",
          "tokens_per_second": 383.0,
          "ttft": 0.259,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.56,
          "status": "Online",
          "tokens_per_second": 175.0,
          "ttft": 0.581,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.28,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.504,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.47,
          "status": "Online",
          "tokens_per_second": 66.0,
          "ttft": 1.223,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.51,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 2.058,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 18:37:33 UTC",
      "results": {
        "Groq": {
          "time": 1.86,
          "status": "Online",
          "tokens_per_second": 347.0,
          "ttft": 0.2,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.25,
          "status": "Online",
          "tokens_per_second": 147.0,
          "ttft": 0.457,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 16.28,
          "status": "Online",
          "tokens_per_second": 82.0,
          "ttft": 1.146,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.75,
          "status": "Online",
          "tokens_per_second": 53.0,
          "ttft": 0.689,
          "streaming_smoothness": 0.135
        },
        "DeepSeek": {
          "time": 31.38,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 1.383,
          "streaming_smoothness": 0.102
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-14 02:25:59 UTC",
      "results": {
        "Groq": {
          "time": 1.42,
          "status": "Online",
          "tokens_per_second": 385.0,
          "ttft": 0.159,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.33,
          "status": "Online",
          "tokens_per_second": 169.0,
          "ttft": 0.35,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.12,
          "status": "Online",
          "tokens_per_second": 52.0,
          "ttft": 0.455,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 23.38,
          "status": "Online",
          "tokens_per_second": 59.0,
          "ttft": 1.13,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.4,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 1.169,
          "streaming_smoothness": 0.08
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    }
  ],
  "reliability_scores": {
    "Groq": 100.0,
    "Together AI": 100.0,
    "Mistral AI": 100.0,
    "OpenAI": 100.0,
    "DeepSeek": 100.0,
    "Anthropic": 0.0,
    "Google": 0.0,
    "Cohere": 0.0,
    "Fireworks": 0.0,
    "Cerebras": 0.0
  },
  "metadata": {
    "version": "3.0",
    "parallel_testing": false,
    "streaming_enabled": true,
    "timeout": 90,
    "retries": 3
  }
}