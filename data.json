{
  "last_updated": "2025-12-11 06:47:15 UTC",
  "prompt": "You are tasked with analyzing the evolution of artificial intelligence from 2010 to 2025. Your response must be comprehensive and well-structured.\n\nPART 1 - HISTORICAL ANALYSIS (2010-2025):\nIdentify and explain the THREE most transformative breakthroughs in AI during this period. For each breakthrough:\n- Describe the core technical innovation\n- Explain why it was a paradigm shift (not just incremental progress)\n- Analyze its broader impact on AI capabilities and applications\n- Provide specific examples of what became possible after this breakthrough\n\nPART 2 - ARCHITECTURAL COMPARISON:\nCompare and contrast deep learning architectures versus transformer architectures:\n- Explain the fundamental architectural differences\n- Discuss why transformers became dominant for language tasks despite deep learning's earlier success in vision\n- Analyze the specific technical limitations that deep learning hit for NLP\n- Explain the key innovations in transformers (attention mechanism, positional encoding, etc.) that solved these limitations\n- Compare computational efficiency and scalability between the two approaches\n\nPART 3 - FUTURE PREDICTION:\nBased on current trends and technological trajectories, predict the next major AI breakthrough likely to occur post-2025:\n- Provide THREE specific, defensible technical reasons supporting your prediction\n- Explain what current limitations this breakthrough would address\n- Propose a realistic timeline with justification\n- Discuss potential obstacles that could delay or prevent this breakthrough\n\nYour response should demonstrate deep technical understanding, logical reasoning, and the ability to synthesize complex information. Aim for 2500-3500 characters with clear structure and specific technical details.",
  "max_tokens": 1000,
  "results": [
    {
      "provider": "Groq",
      "model": "llama-3.3-70b-versatile",
      "status": "Online",
      "time": 1.54,
      "ttft": 0.257,
      "tokens_per_second": 356.0,
      "streaming_smoothness": 0,
      "output_tokens": 548,
      "character_count": 2194,
      "cost_per_request": 0.0,
      "full_response": "**Part 1 - Historical Analysis (2010-2025)**\n\n1. **Deep Learning (2010)**: Core innovation was the use of convolutional neural networks (CNNs) and recurrent neural networks (RNNs) to learn hierarchies of features. This was a paradigm shift because it enabled learning from raw data, rather than relying on hand-engineered features. Impact: enabled state-of-the-art performance in image and speech recognition. Example: self-driving cars' ability to recognize objects.\n2. **Generative Adversarial Networks (GANs) (2014)**: Core innovation was the use of competing neural networks to generate new data. This was a paradigm shift because it enabled generating realistic synthetic data. Impact: enabled new applications in data augmentation and style transfer. Example: generating realistic faces for data augmentation.\n3. **Transformers (2017)**: Core innovation was the use of self-attention mechanisms to process sequential data. This was a paradigm shift because it enabled parallelization of sequential data processing. Impact: enabled state-of-the-art performance in natural language processing (NLP) tasks. Example: language translation and text summarization.\n\n**Part 2 - Architectural Comparison**\n\nDeep learning architectures (e.g., CNNs, RNNs) vs. transformer architectures: \n- Fundamental difference: deep learning relies on recurrent or convolutional layers, while transformers rely on self-attention mechanisms.\n- Transformers became dominant for language tasks due to their ability to parallelize sequential data processing, addressing deep learning's limitations in handling long-range dependencies.\n- Key innovations in transformers: attention mechanism, positional encoding, and multi-head attention.\n\n**Part 3 - Future Prediction**\n\nNext major AI breakthrough: **multimodal learning**. \n- Technical reasons: (1) increasing availability of multimodal data, (2) advancements in transformer architectures, and (3) need for more generalizable AI models.\n- Current limitations: inability to effectively integrate and process multiple data modalities.\n- Realistic timeline: 2028-2030.\n- Obstacles: lack of large-scale multimodal datasets, complexity of integrating multiple modalities.",
      "response_preview": "**Part 1 - Historical Analysis (2010-2025)**\n\n1. **Deep Learning (2010)**: Core innovation was the use of convolutional neural networks (CNNs) and recurrent neural networks (RNNs) to learn hierarchies...",
      "error_info": null
    },
    {
      "provider": "Together AI",
      "model": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
      "status": "Online",
      "time": 5.7,
      "ttft": 0.307,
      "tokens_per_second": 206.0,
      "streaming_smoothness": 0,
      "output_tokens": 1175,
      "character_count": 4702,
      "cost_per_request": 0.00142,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\nIn the last 15 years, AI has experienced tremendous growth, driven by three transformative breakthroughs: the emergence of deep learning, the development of Generative Adversarial Networks (GANs), and the introduction of transformer architectures.\n\n1. **Deep Learning (2010-2012)**\nCore technical innovation: Deep neural networks with multiple layers and dropout regularization.\nParadigm shift: Deep learning enabled the training of incredibly large models, capable of learning complex patterns in data. This was possible due to advancements in computing power, large datasets, and new regularization techniques.\nBroader impact: Deep learning led to significant improvements in computer vision and speech recognition. It also opened the door for reinforcement learning and robotics applications.\nExample: ImageNet Large Scale Visual Recognition Challenge (ILSVRC) saw a rapid decline in error rates, with top-5 error decreasing from 25.8% in 2010 to 5.1% in 2015.\n\n2. **Generative Adversarial Networks (GANs) (2014)**\nCore technical innovation: A generator network produces synthetic data, while a discriminator network evaluates its quality.\nParadigm shift: GANs introduced a new framework for unsupervised learning and generative modeling, enabling AI to produce realistic and diverse synthetic data.\nBroader impact: GANs have been applied in various domains, including computer-generated images, video, music, and even protein engineering.\nExample: StyleGAN (2018) produced incredibly realistic images of faces, animals, and objects, furthering AI's creative potential.\n\n3. **Transformer Architectures (2017)**\nCore technical innovation: Self-attention mechanisms and positional encoding enable parallelization and sequence modeling without recurrent connections.\nParadigm shift: Transformers revolutionized natural language processing (NLP) tasks, such as language translation, question-answering, and text generation.\nBroader impact: Transformers have been applied to various sequence tasks, including speech recognition, music generation, and even task-oriented dialogue.\nExample: BERT (2018) achieved state-of-the-art results on the GLUE benchmark, pushing the boundaries of NLP capabilities.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\nDeep learning and transformer architectures differ fundamentally in their approach to sequence modeling.\n\n**Deep Learning Architectures:**\nRNNs and LSTMs rely on recurrent connections, which limit parallelization and make them computationally expensive for long sequences.\n\n**Transformer Architectures:**\nSelf-attention mechanisms and positional encoding enable parallelization and efficient processing of long sequences. This led to transformers dominating NLP tasks.\n\nThe technical limitations of deep learning for NLP were:\n\n* Sequential processing, limiting parallelization\n* Difficulty modeling long-term dependencies\n* Inability to capture complex contextual relationships\n\nTransformers solved these limitations with:\n\n* Self-attention mechanisms for contextual relationships\n* Positional encoding for sequence information\n* Parallelization for efficient processing\n\nComputational efficiency and scalability:\n\n* Transformers are more computationally efficient due to parallelization\n* Deep learning architectures can be more scalable with specialized hardware (GPUs)\n\n**PART 3 - FUTURE PREDICTION**\n\nBased on current trends, I predict the next major AI breakthrough will be the development of **Cognitive Architectures** that combine symbolic reasoning, deep learning, and meta-learning.\n\n**Three Technical Reasons:**\n\n1. **Hybrid Approaches**: Combining symbolic reasoning with deep learning will enable more robust, interpretable, and generalizable AI systems.\n2. **Meta-Learning**: Developing meta-learning algorithms will facilitate the creation of versatile, adaptable, and autonomous AI agents.\n3. **Embodied Cognition**: Integrating cognitive architectures with embodied and sensorimotor learning will enable AI systems to learn and reason in a more human-like manner.\n\n**Current Limitations:**\n\n* Current AI systems lack robustness, interpretability, and generalizability\n* Limited ability to learn and reason in dynamic, uncertain environments\n\n**Realistic Timeline:**\n\nI predict the emergence of cognitive architectures within the next 5-10 years, driven by advancements in meta-learning, symbolic reasoning, and embodied cognition.\n\n**Potential Obstacles:**\n\n* Integrating diverse AI techniques into coherent cognitive architectures\n* Overcoming the complexity and computational requirements of hybrid approaches\n* Resolving the trade-offs between interpretability, generalizability, and performance",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\nIn the last 15 years, AI has experienced tremendous growth, driven by three transformative breakthroughs: the emergence of deep learning, the development ...",
      "error_info": null
    },
    {
      "provider": "Mistral AI",
      "model": "mistral-large-latest",
      "status": "Online",
      "time": 23.5,
      "ttft": 0.509,
      "tokens_per_second": 42.0,
      "streaming_smoothness": 0.525,
      "output_tokens": 997,
      "character_count": 3988,
      "cost_per_request": 0.00686,
      "full_response": "# **The Evolution of Artificial Intelligence (2010\u20132025): A Comprehensive Analysis**\n\n## **PART 1 \u2013 HISTORICAL ANALYSIS (2010\u20132025): Three Transformative Breakthroughs**\n\n### **1. Deep Learning Revolution (2012\u20132015): The Rise of Neural Networks**\n#### **Core Technical Innovation**\nThe breakthrough came with **AlexNet (2012)**, a deep convolutional neural network (CNN) that won the ImageNet competition by a significant margin. Key innovations included:\n- **ReLU activation functions** (faster training than sigmoid/tanh)\n- **Dropout regularization** (preventing overfitting)\n- **GPU acceleration** (enabling training of deeper networks)\n- **Data augmentation** (improving generalization)\n\n#### **Paradigm Shift**\nBefore 2012, AI relied on handcrafted features (e.g., SIFT, HOG) and shallow models (SVMs, decision trees). Deep learning **automated feature extraction**, eliminating the need for manual engineering. This was not just incremental\u2014it was a **fundamental shift from rule-based to data-driven learning**.\n\n#### **Broader Impact**\n- **Computer Vision:** Object detection (YOLO, Faster R-CNN), facial recognition, medical imaging (e.g., detecting tumors in X-rays).\n- **Speech Recognition:** Deep neural networks replaced Gaussian Mixture Models (GMMs), enabling Siri, Alexa, and real-time transcription.\n- **Autonomous Systems:** Tesla\u2019s Autopilot, Waymo\u2019s self-driving cars.\n\n#### **What Became Possible?**\n- **Real-time image classification** (e.g., Facebook\u2019s automatic photo tagging).\n- **Superhuman performance in narrow domains** (e.g., AlphaGo beating Lee Sedol in 2016).\n- **Transfer learning** (pretrained models like VGG, ResNet reused across tasks).\n\n---\n\n### **2. Transformer Architecture (2017\u20132020): The Foundation of Modern NLP**\n#### **Core Technical Innovation**\nThe **Transformer (2017, \"Attention Is All You Need\")** introduced:\n- **Self-attention mechanism** (capturing long-range dependencies in sequences).\n- **Positional encoding** (replacing recurrence with parallelizable attention).\n- **Multi-head attention** (allowing the model to focus on different parts of input simultaneously).\n- **Scalability** (enabling training on massive datasets like Common Crawl).\n\n#### **Paradigm Shift**\nBefore Transformers, NLP relied on **recurrent neural networks (RNNs)** and **LSTMs**, which suffered from:\n- **Vanishing gradients** (struggling with long sequences).\n- **Sequential processing** (slow training, no parallelization).\n- **Limited context windows** (poor handling of long-range dependencies).\n\nTransformers **eliminated recurrence entirely**, enabling **parallel training** and **scalable language models** (e.g., BERT, GPT-3).\n\n#### **Broader Impact**\n- **Language Understanding:** BERT (2018) achieved state-of-the-art in 11 NLP tasks (e.g., sentiment analysis, question answering).\n- **Generative AI:** GPT-3 (2020) demonstrated **few-shot learning**, generating human-like text.\n- **Multimodal AI:** Models like CLIP (2021) and DALL-E (2021) combined text and image understanding.\n\n#### **What Became Possible?**\n- **Conversational AI** (e.g., ChatGPT, Google Bard).\n- **Code generation** (e.g., GitHub Copilot).\n- **Zero-shot and few-shot learning** (models performing tasks with minimal examples).\n\n---\n\n### **3. Foundation Models & Scaling Laws (2020\u20132025): The Era of General-Purpose AI**\n#### **Core Technical Innovation**\nThe rise of **large-scale pretrained models** (e.g., GPT-3, PaLM, LLaMA) was enabled by:\n- **Scaling laws** (empirical observation that model performance improves predictably with more data, compute, and parameters).\n- **Self-supervised learning** (training on raw text without labeled data).\n- **Efficient architectures** (e.g., sparse attention, mixture-of-experts).\n- **Hardware advancements** (TPUs, A100 GPUs, distributed training).\n\n#### **Paradigm Shift**\nBefore 2020, AI models were **task-specific** (e.g., a separate model for translation, another for summarization). Foundation models **generalized across",
      "response_preview": "# **The Evolution of Artificial Intelligence (2010\u20132025): A Comprehensive Analysis**\n\n## **PART 1 \u2013 HISTORICAL ANALYSIS (2010\u20132025): Three Transformative Breakthroughs**\n\n### **1. Deep Learning Revolu...",
      "error_info": null
    },
    {
      "provider": "OpenAI",
      "model": "gpt-4o-mini",
      "status": "Online",
      "time": 24.47,
      "ttft": 0.985,
      "tokens_per_second": 58.0,
      "streaming_smoothness": 0,
      "output_tokens": 1418,
      "character_count": 5671,
      "cost_per_request": 0.00092,
      "full_response": "# PART 1 - HISTORICAL ANALYSIS (2010-2025)\n\n## Breakthrough 1: Deep Learning Revolution (2012)\n### Core Technical Innovation\nThe introduction of deep convolutional neural networks (CNNs) for image recognition, particularly exemplified by AlexNet at the ImageNet competition in 2012, marked a significant point in AI evolution. The architecture incorporated multiple layers of convolutions, ReLU activation functions, and dropout for regularization.\n\n### Paradigm Shift\nThis work was a paradigm shift because it demonstrated that neural networks could achieve state-of-the-art performance on large-scale datasets using massive parallel processing via GPUs. It contradicted prevailing beliefs about the limitations of neural networks and highlighted their potential to learn complex features automatically.\n\n### Broader Impact\nThe broader impact was multifaceted, enabling significant advancements in computer vision, such as facial recognition, autonomous vehicles, and medical imaging. Post-breakthrough, applications like Google Photos and self-driving technology became feasible due to enhanced image classification.\n\n## Breakthrough 2: Sequence-to-Sequence Models (2014)\n### Core Technical Innovation\nThe introduction of sequence-to-sequence (Seq2Seq) models by Google in 2014 allowed for effective handling of variable-length sequences in tasks such as machine translation. These models employed LSTM networks to encode input sequences and decode them, revolutionizing text processing.\n\n### Paradigm Shift\nThis approach was radical as it moved beyond traditional statistical methods, offering a unified framework for various sequential tasks. Its success showed that deep learning could generalize across domains, increasing the scope of NLP tasks that could be addressed with similar architectures.\n\n### Broader Impact\nSeq2Seq models paved the way for applications such as real-time translation (e.g., Google Translate), chatbots, and text summarization systems, allowing for deeper interaction between humans and machines through more natural language processing capabilities.\n\n## Breakthrough 3: Transformer Architecture (2017)\n### Core Technical Innovation\nThe introduction of the transformer architecture by Vaswani et al. in 2017 eliminated recurrence with self-attention mechanisms and allowed for parallel processing, fundamentally altering how sequential data was processed.\n\n### Paradigm Shift\nThis shift reduced training times drastically and increased scalability, which was a game-changer for NLP and beyond. It demonstrated that models could capture long-range dependencies without the constraints of previous recurrent architectures.\n\n### Broader Impact\nTransformers enabled models like BERT and GPT-3, capable of generating coherent, human-like text. This led to a surge in AI applications in conversational agents, content creation, and even coding assistance, fundamentally changing the interaction dynamics in technology.\n\n# PART 2 - ARCHITECTURAL COMPARISON\n\n## Fundamental Architectural Differences\nDeep learning architectures, particularly CNNs and LSTMs, rely on sequential processing and fixed input sizes. They use convolutional layers or recurrence to extract features. Transformers, on the other hand, use self-attention mechanisms to weigh the relevance of different input tokens simultaneously, allowing for parallelization and better long-range context capture.\n\n## Why Transformers Became Dominant \nTransformers excelled in NLP despite the earlier success of deep learning models in vision due to their ability to handle varying input lengths without structurally altering the architecture. Deep learning\u2019s methods often struggle with long sequences due to vanishing gradients in LSTM layers.\n\n## Specific Technical Limitations in Deep Learning for NLP \nDeep learning approaches became limited by their inherently sequential nature\u2014namely, the inability to efficiently capture long-range dependencies and contextual relationships in language. This resulted in inefficient training and hindered performance as sequences grew longer.\n\n## Key Innovations in Transformers\nThe attention mechanism allows the model to focus on relevant parts of the input sequence dynamically, and positional encoding gives each token a sense of order. These innovations enable simultaneous processing of input data while still maintaining contextual integrity, crucial for languages with complex structures.\n\n## Computational Efficiency and Scalability\nTransformers demonstrated superior scalability due to their parallel processing ability. They require significantly less time to train on large datasets compared to sequential RNNs, and the ability to leverage attention makes them ideal for tasks with high data dimensionality.\n\n# PART 3 - FUTURE PREDICTION\n\n## Next Major AI Breakthrough: Generalized AI Assistants (Post-2025)\n### Technical Reasons Supporting Prediction\n1. **Contextual Understanding**: Advances in knowledge integration and context-aware processing promise more intelligent AI systems capable of understanding nuanced human language.\n2. **Multi-modal Learning**: Combining text, image, and potentially audio into a unified model could lead to more versatile AI applications.\n3. **Self-supervised Learning**: Continued improvements in self-supervised learning could allow models to learn from fewer labeled data, enhancing generalization and applicability across domains.\n\n### Addressing Current Limitations\nThis would address limitations in AI's capability to truly comprehend and generate responses in ways that consider the emotional and contextual subtleties of human communication, leading to improved interpersonal AI interactions.",
      "response_preview": "# PART 1 - HISTORICAL ANALYSIS (2010-2025)\n\n## Breakthrough 1: Deep Learning Revolution (2012)\n### Core Technical Innovation\nThe introduction of deep convolutional neural networks (CNNs) for image rec...",
      "error_info": null
    },
    {
      "provider": "DeepSeek",
      "model": "deepseek-chat",
      "status": "Online",
      "time": 40.04,
      "ttft": 1.5,
      "tokens_per_second": 31.0,
      "streaming_smoothness": 0.113,
      "output_tokens": 1225,
      "character_count": 4901,
      "cost_per_request": 0.0004,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1.  **Deep Learning Revolution (c. 2012):**\n    *   **Core Innovation:** The effective training of very deep convolutional neural networks (CNNs) using GPUs, backpropagation, and techniques like ReLU and Dropout.\n    *   **Paradigm Shift:** Moved AI from hand-engineered feature extraction to end-to-end learned feature hierarchies. It proved that scaling neural networks with data and compute yielded qualitatively better performance.\n    *   **Impact & Example:** Enabled superhuman performance on image classification (AlexNet on ImageNet). This breakthrough directly catalyzed the modern AI boom, making perception tasks (vision, speech) a solved problem for many applications, leading to facial recognition, advanced medical imaging, and robust voice assistants.\n\n2.  **Transformer Architecture (2017):**\n    *   **Core Innovation:** The \"Attention is All You Need\" paper introduced the scaled dot-product attention mechanism and the encoder-decoder stack without recurrence.\n    *   **Paradigm Shift:** Replaced sequential processing (RNNs/LSTMs) with parallelizable self-attention, allowing models to weigh the importance of all tokens in a sequence simultaneously, regardless of distance.\n    *   **Impact & Example:** Solved the long-range dependency and training parallelism bottlenecks of RNNs. It made the training of massive language models feasible (BERT, GPT series), leading to few-shot learning, coherent long-form text generation, and foundation models.\n\n3.  **Emergence of Foundation Models & Scaling Laws (2020-2022):**\n    *   **Core Innovation:** The empirical discovery of predictable power-law scaling between model size, dataset size, compute, and performance (e.g., Chinchilla Laws).\n    *   **Paradigm Shift:** Moved AI from task-specific models to a single, massively scaled \"pre-train then adapt\" paradigm. It demonstrated that scaling alone could unlock emergent abilities (reasoning, code generation) not explicitly trained for.\n    *   **Impact & Example:** Enabled general-purpose AI assistants (ChatGPT, Copilot) capable of in-context learning, instruction following, and multi-task performance without fine-tuning, fundamentally changing human-AI interaction.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\n*   **Fundamental Differences:** Deep learning (specifically CNNs/RNNs) relies on **local, inductive biases**\u2014CNNs use convolutional filters for spatial locality, RNNs use recurrence for sequential order. Transformers use **global, content-based attention**, dynamically connecting any two positions in the input.\n*   **Dominance in NLP:** CNNs excelled in vision due to translation invariance, a perfect match for images. RNNs, the prior NLP standard, were fundamentally limited by **sequential processing** (slow training/inference) and **vanishing gradients**, struggling with long-range dependencies.\n*   **Transformer Innovations:**\n    1.  **Self-Attention:** Computes relationships between all words in parallel, solving long-range dependency.\n    2.  **Positional Encoding:** Injects order information since attention is permutation-invariant.\n    3.  **Layer Stacking & Residual Connections:** Enables very deep, stable models.\n*   **Efficiency & Scalability:** Transformers are vastly more **parallelizable** during training than RNNs, perfect for GPU/TPU clusters. However, their **inference** is computationally heavy (O(n\u00b2) memory for attention). CNNs are more efficient for fixed-size perceptual tasks, but transformers' scalability and generality made them the dominant architecture for multimodal foundation models.\n\n**PART 3 - FUTURE PREDICTION**\n\n**Prediction:** The next major breakthrough will be the widespread adoption of **highly sample-efficient, planning-based hybrid architectures** (e.g., AI systems integrating learned models with explicit algorithmic reasoning and world models).\n\n**Three Supporting Reasons:**\n1.  **Limitation of Autoregressive Next-Token Prediction:** Current LLMs lack deliberate, multi-step planning, leading to hallucinations and poor performance on complex reasoning (e.g., advanced mathematics, strategic planning).\n2.  **Success of Alpha-type Models:** AlphaGo, AlphaFold, and AlphaGeometry demonstrate that combining learned models with Monte Carlo Tree Search (MCTS) or symbolic engines yields superhuman, reliable performance in constrained domains.\n3.  **Economic Pressure for Reliability:** Enterprise adoption requires verifiable, logical consistency, not just plausible generation.\n\n**Limitations Addressed:** This would address poor logical deduction, factual inconsistency, and the inability to \"think before acting\" in digital or physical environments.\n\n**Timeline:** 2026-2028 for robust prototypes in specific domains (scientific discovery, advanced code generation); 2030+ for general integration. Justification: Research is already active (OpenAI's \"Q*",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1.  **Deep Learning Revolution (c. 2012):**\n    *   **Core Innovation:** The effective training of very deep convolutional neural networks (CNNs) using GP...",
      "error_info": null
    },
    {
      "provider": "Anthropic",
      "model": "claude-3-5-sonnet-20241022",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-11 06:45:30 UTC"
      }
    },
    {
      "provider": "Google",
      "model": "gemini-1.5-flash",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-11 06:45:37 UTC"
      }
    },
    {
      "provider": "Cohere",
      "model": "command-r-plus",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-11 06:46:11 UTC"
      }
    },
    {
      "provider": "Fireworks",
      "model": "accounts/fireworks/models/llama-v3p1-70b-instruct",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-11 06:47:06 UTC"
      }
    },
    {
      "provider": "Cerebras",
      "model": "llama3.1-70b",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-11 06:47:14 UTC"
      }
    }
  ],
  "history": [
    {
      "timestamp": "2025-12-05 00:15:33 UTC",
      "results": {
        "Groq": {
          "time": 3.11,
          "status": "Online",
          "tokens_per_second": 300.0
        },
        "Together AI": {
          "time": 8.89,
          "status": "Online",
          "tokens_per_second": 95.0
        },
        "OpenAI": {
          "time": 19.47,
          "status": "Online",
          "tokens_per_second": 51.0
        },
        "Mistral AI": {
          "time": 22.32,
          "status": "Online",
          "tokens_per_second": 45.0
        },
        "DeepSeek": {
          "time": 40.69,
          "status": "Online",
          "tokens_per_second": 25.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-05 01:10:56 UTC",
      "results": {
        "Groq": {
          "time": 2.96,
          "status": "Online",
          "tokens_per_second": 274.0
        },
        "Together AI": {
          "time": 4.41,
          "status": "Online",
          "tokens_per_second": 171.0
        },
        "OpenAI": {
          "time": 25.67,
          "status": "Online",
          "tokens_per_second": 38.0
        },
        "Mistral AI": {
          "time": 27.35,
          "status": "Online",
          "tokens_per_second": 37.0
        },
        "DeepSeek": {
          "time": 41.0,
          "status": "Online",
          "tokens_per_second": 24.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-05 01:36:17 UTC",
      "results": {
        "Groq": {
          "time": 2.45,
          "status": "Online",
          "tokens_per_second": 383.0
        },
        "Together AI": {
          "time": 5.48,
          "status": "Online",
          "tokens_per_second": 142.0
        },
        "OpenAI": {
          "time": 20.18,
          "status": "Online",
          "tokens_per_second": 50.0
        },
        "Mistral AI": {
          "time": 22.42,
          "status": "Online",
          "tokens_per_second": 45.0
        },
        "DeepSeek": {
          "time": 40.64,
          "status": "Online",
          "tokens_per_second": 25.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-05 02:09:39 UTC",
      "results": {
        "Groq": {
          "time": 2.66,
          "status": "Online",
          "tokens_per_second": 321.0
        },
        "Together AI": {
          "time": 5.72,
          "status": "Online",
          "tokens_per_second": 145.0
        },
        "OpenAI": {
          "time": 17.44,
          "status": "Online",
          "tokens_per_second": 57.0
        },
        "Mistral AI": {
          "time": 22.67,
          "status": "Online",
          "tokens_per_second": 44.0
        },
        "DeepSeek": {
          "time": 40.06,
          "status": "Online",
          "tokens_per_second": 25.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-05 06:43:29 UTC",
      "results": {
        "Groq": {
          "time": 2.75,
          "status": "Online",
          "tokens_per_second": 291.0
        },
        "Together AI": {
          "time": 4.36,
          "status": "Online",
          "tokens_per_second": 182.0
        },
        "OpenAI": {
          "time": 11.27,
          "status": "Online",
          "tokens_per_second": 89.0
        },
        "Mistral AI": {
          "time": 25.49,
          "status": "Online",
          "tokens_per_second": 39.0
        },
        "DeepSeek": {
          "time": 38.07,
          "status": "Online",
          "tokens_per_second": 25.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-05 12:58:39 UTC",
      "results": {
        "Groq": {
          "time": 3.98,
          "status": "Online",
          "tokens_per_second": 206.0
        },
        "Together AI": {
          "time": 6.17,
          "status": "Online",
          "tokens_per_second": 151.0
        },
        "OpenAI": {
          "time": 17.34,
          "status": "Online",
          "tokens_per_second": 58.0
        },
        "Mistral AI": {
          "time": 21.62,
          "status": "Online",
          "tokens_per_second": 46.0
        },
        "DeepSeek": {
          "time": 37.85,
          "status": "Online",
          "tokens_per_second": 26.0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0
        }
      }
    },
    {
      "timestamp": "2025-12-05 19:06:40 UTC",
      "results": {
        "Groq": {
          "time": 1.83,
          "status": "Online",
          "tokens_per_second": 324.0,
          "ttft": 0.277,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.82,
          "status": "Online",
          "tokens_per_second": 124.0,
          "ttft": 0.407,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.83,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.686,
          "streaming_smoothness": 0.327
        },
        "OpenAI": {
          "time": 20.57,
          "status": "Online",
          "tokens_per_second": 65.0,
          "ttft": 1.291,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 29.5,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.4,
          "streaming_smoothness": 0.073
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-05 19:26:10 UTC",
      "results": {
        "Groq": {
          "time": 1.34,
          "status": "Online",
          "tokens_per_second": 397.0,
          "ttft": 0.233,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.15,
          "status": "Online",
          "tokens_per_second": 167.0,
          "ttft": 0.637,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.18,
          "status": "Online",
          "tokens_per_second": 73.0,
          "ttft": 1.133,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.93,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.479,
          "streaming_smoothness": 0.112
        },
        "DeepSeek": {
          "time": 32.29,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 1.652,
          "streaming_smoothness": 0.05
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-06 02:03:29 UTC",
      "results": {
        "Groq": {
          "time": 1.41,
          "status": "Online",
          "tokens_per_second": 339.0,
          "ttft": 0.287,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.94,
          "status": "Online",
          "tokens_per_second": 190.0,
          "ttft": 1.135,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.74,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 2.127,
          "streaming_smoothness": 0.252
        },
        "OpenAI": {
          "time": 23.08,
          "status": "Online",
          "tokens_per_second": 59.0,
          "ttft": 1.259,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 34.89,
          "status": "Online",
          "tokens_per_second": 36.0,
          "ttft": 1.665,
          "streaming_smoothness": 0.066
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-06 06:39:46 UTC",
      "results": {
        "Groq": {
          "time": 1.67,
          "status": "Online",
          "tokens_per_second": 358.0,
          "ttft": 0.25,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.13,
          "status": "Online",
          "tokens_per_second": 156.0,
          "ttft": 1.956,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.37,
          "status": "Online",
          "tokens_per_second": 54.0,
          "ttft": 0.465,
          "streaming_smoothness": 0.157
        },
        "OpenAI": {
          "time": 21.59,
          "status": "Online",
          "tokens_per_second": 64.0,
          "ttft": 2.174,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.05,
          "status": "Online",
          "tokens_per_second": 34.0,
          "ttft": 1.784,
          "streaming_smoothness": 0.028
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-06 12:54:36 UTC",
      "results": {
        "Groq": {
          "time": 1.59,
          "status": "Online",
          "tokens_per_second": 428.0,
          "ttft": 0.195,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.13,
          "status": "Online",
          "tokens_per_second": 141.0,
          "ttft": 2.101,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.86,
          "status": "Online",
          "tokens_per_second": 47.0,
          "ttft": 1.111,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.61,
          "status": "Online",
          "tokens_per_second": 59.0,
          "ttft": 1.299,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 37.17,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.431,
          "streaming_smoothness": 0.06
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-06 18:37:29 UTC",
      "results": {
        "Groq": {
          "time": 1.73,
          "status": "Online",
          "tokens_per_second": 328.0,
          "ttft": 0.269,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.3,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.321,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.75,
          "status": "Online",
          "tokens_per_second": 47.0,
          "ttft": 0.937,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.53,
          "status": "Online",
          "tokens_per_second": 60.0,
          "ttft": 1.129,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 30.91,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 1.358,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 02:25:22 UTC",
      "results": {
        "Groq": {
          "time": 1.68,
          "status": "Online",
          "tokens_per_second": 320.0,
          "ttft": 0.199,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.37,
          "status": "Online",
          "tokens_per_second": 115.0,
          "ttft": 0.685,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.59,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.738,
          "streaming_smoothness": 0.192
        },
        "OpenAI": {
          "time": 20.78,
          "status": "Online",
          "tokens_per_second": 65.0,
          "ttft": 1.14,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 36.26,
          "status": "Online",
          "tokens_per_second": 34.0,
          "ttft": 1.497,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 06:39:23 UTC",
      "results": {
        "Groq": {
          "time": 1.54,
          "status": "Online",
          "tokens_per_second": 336.0,
          "ttft": 0.197,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.86,
          "status": "Online",
          "tokens_per_second": 144.0,
          "ttft": 0.436,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 16.83,
          "status": "Online",
          "tokens_per_second": 80.0,
          "ttft": 1.303,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.56,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 1.576,
          "streaming_smoothness": 0.067
        },
        "DeepSeek": {
          "time": 34.65,
          "status": "Online",
          "tokens_per_second": 36.0,
          "ttft": 1.226,
          "streaming_smoothness": 0.065
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 12:52:59 UTC",
      "results": {
        "Groq": {
          "time": 1.45,
          "status": "Online",
          "tokens_per_second": 350.0,
          "ttft": 0.143,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.81,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.291,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.96,
          "status": "Online",
          "tokens_per_second": 49.0,
          "ttft": 0.471,
          "streaming_smoothness": 0.799
        },
        "OpenAI": {
          "time": 22.43,
          "status": "Online",
          "tokens_per_second": 61.0,
          "ttft": 1.374,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.79,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.366,
          "streaming_smoothness": 0.042
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 18:37:46 UTC",
      "results": {
        "Groq": {
          "time": 1.38,
          "status": "Online",
          "tokens_per_second": 396.0,
          "ttft": 0.158,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 11.08,
          "status": "Online",
          "tokens_per_second": 117.0,
          "ttft": 0.98,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.22,
          "status": "Online",
          "tokens_per_second": 69.0,
          "ttft": 1.189,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.5,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 3.31,
          "streaming_smoothness": 0.241
        },
        "DeepSeek": {
          "time": 33.12,
          "status": "Online",
          "tokens_per_second": 38.0,
          "ttft": 3.082,
          "streaming_smoothness": 0.023
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 02:11:03 UTC",
      "results": {
        "Groq": {
          "time": 1.8,
          "status": "Online",
          "tokens_per_second": 375.0,
          "ttft": 0.266,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.83,
          "status": "Online",
          "tokens_per_second": 173.0,
          "ttft": 0.271,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.47,
          "status": "Online",
          "tokens_per_second": 65.0,
          "ttft": 1.042,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.16,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 3.077,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.87,
          "status": "Online",
          "tokens_per_second": 31.0,
          "ttft": 1.378,
          "streaming_smoothness": 0.09
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 06:48:36 UTC",
      "results": {
        "Groq": {
          "time": 1.74,
          "status": "Online",
          "tokens_per_second": 377.0,
          "ttft": 0.225,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 13.09,
          "status": "Online",
          "tokens_per_second": 92.0,
          "ttft": 0.437,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.19,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.137,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.39,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 2.397,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.6,
          "status": "Online",
          "tokens_per_second": 30.0,
          "ttft": 1.27,
          "streaming_smoothness": 0.033
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 13:00:14 UTC",
      "results": {
        "Groq": {
          "time": 2.12,
          "status": "Online",
          "tokens_per_second": 347.0,
          "ttft": 0.276,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.36,
          "status": "Online",
          "tokens_per_second": 127.0,
          "ttft": 0.471,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.23,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 1.478,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 24.11,
          "status": "Online",
          "tokens_per_second": 41.0,
          "ttft": 0.711,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.71,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.107,
          "streaming_smoothness": 0.084
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 18:43:36 UTC",
      "results": {
        "Groq": {
          "time": 1.88,
          "status": "Online",
          "tokens_per_second": 350.0,
          "ttft": 0.271,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.49,
          "status": "Online",
          "tokens_per_second": 195.0,
          "ttft": 0.364,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.68,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 1.341,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.7,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 1.074,
          "streaming_smoothness": 0.47
        },
        "DeepSeek": {
          "time": 32.09,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 0.935,
          "streaming_smoothness": 0.071
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 02:09:54 UTC",
      "results": {
        "Groq": {
          "time": 1.97,
          "status": "Online",
          "tokens_per_second": 416.0,
          "ttft": 0.198,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.4,
          "status": "Online",
          "tokens_per_second": 143.0,
          "ttft": 0.309,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.03,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 2.049,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.46,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.665,
          "streaming_smoothness": 0.51
        },
        "DeepSeek": {
          "time": 38.93,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.506,
          "streaming_smoothness": 0.021
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 06:45:12 UTC",
      "results": {
        "Groq": {
          "time": 1.66,
          "status": "Online",
          "tokens_per_second": 334.0,
          "ttft": 0.258,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.28,
          "status": "Online",
          "tokens_per_second": 157.0,
          "ttft": 0.446,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.87,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 1.486,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 32.11,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 1.192,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 42.03,
          "status": "Online",
          "tokens_per_second": 29.0,
          "ttft": 2.249,
          "streaming_smoothness": 0.061
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 13:02:20 UTC",
      "results": {
        "Groq": {
          "time": 1.69,
          "status": "Online",
          "tokens_per_second": 388.0,
          "ttft": 0.153,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.25,
          "status": "Online",
          "tokens_per_second": 190.0,
          "ttft": 0.35,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.22,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.225,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 26.15,
          "status": "Online",
          "tokens_per_second": 37.0,
          "ttft": 3.278,
          "streaming_smoothness": 0.494
        },
        "DeepSeek": {
          "time": 38.27,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.353,
          "streaming_smoothness": 0.037
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 18:39:45 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 365.0,
          "ttft": 0.168,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.55,
          "status": "Online",
          "tokens_per_second": 151.0,
          "ttft": 0.651,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 23.07,
          "status": "Online",
          "tokens_per_second": 64.0,
          "ttft": 1.297,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 26.09,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 1.506,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 31.69,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.187,
          "streaming_smoothness": 0.077
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 02:11:51 UTC",
      "results": {
        "Groq": {
          "time": 1.75,
          "status": "Online",
          "tokens_per_second": 403.0,
          "ttft": 0.366,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.22,
          "status": "Online",
          "tokens_per_second": 207.0,
          "ttft": 0.582,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.95,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 2.078,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 25.37,
          "status": "Online",
          "tokens_per_second": 55.0,
          "ttft": 1.827,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.45,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.231,
          "streaming_smoothness": 0.093
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 06:45:39 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 376.0,
          "ttft": 0.189,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.16,
          "status": "Online",
          "tokens_per_second": 146.0,
          "ttft": 0.333,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.43,
          "status": "Online",
          "tokens_per_second": 50.0,
          "ttft": 1.996,
          "streaming_smoothness": 0.299
        },
        "OpenAI": {
          "time": 26.86,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.981,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.07,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.192,
          "streaming_smoothness": 0.027
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 13:02:42 UTC",
      "results": {
        "Groq": {
          "time": 1.36,
          "status": "Online",
          "tokens_per_second": 325.0,
          "ttft": 0.205,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.29,
          "status": "Online",
          "tokens_per_second": 147.0,
          "ttft": 0.31,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.6,
          "status": "Online",
          "tokens_per_second": 42.0,
          "ttft": 1.082,
          "streaming_smoothness": 0.488
        },
        "OpenAI": {
          "time": 24.1,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 1.467,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.88,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.121,
          "streaming_smoothness": 0.109
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 18:42:03 UTC",
      "results": {
        "Groq": {
          "time": 1.7,
          "status": "Online",
          "tokens_per_second": 379.0,
          "ttft": 0.269,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.25,
          "status": "Online",
          "tokens_per_second": 178.0,
          "ttft": 0.217,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.84,
          "status": "Online",
          "tokens_per_second": 60.0,
          "ttft": 1.331,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.92,
          "status": "Online",
          "tokens_per_second": 48.0,
          "ttft": 0.509,
          "streaming_smoothness": 0.258
        },
        "DeepSeek": {
          "time": 31.5,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.568,
          "streaming_smoothness": 0.1
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 02:13:30 UTC",
      "results": {
        "Groq": {
          "time": 1.5,
          "status": "Online",
          "tokens_per_second": 380.0,
          "ttft": 0.201,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.78,
          "status": "Online",
          "tokens_per_second": 146.0,
          "ttft": 0.258,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 18.95,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 1.227,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.36,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 0.479,
          "streaming_smoothness": 0.496
        },
        "DeepSeek": {
          "time": 39.35,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.931,
          "streaming_smoothness": 0.099
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 06:47:15 UTC",
      "results": {
        "Groq": {
          "time": 1.54,
          "status": "Online",
          "tokens_per_second": 356.0,
          "ttft": 0.257,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.7,
          "status": "Online",
          "tokens_per_second": 206.0,
          "ttft": 0.307,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.5,
          "status": "Online",
          "tokens_per_second": 42.0,
          "ttft": 0.509,
          "streaming_smoothness": 0.525
        },
        "OpenAI": {
          "time": 24.47,
          "status": "Online",
          "tokens_per_second": 58.0,
          "ttft": 0.985,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.04,
          "status": "Online",
          "tokens_per_second": 31.0,
          "ttft": 1.5,
          "streaming_smoothness": 0.113
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    }
  ],
  "reliability_scores": {
    "Groq": 100.0,
    "Together AI": 100.0,
    "OpenAI": 100.0,
    "Mistral AI": 100.0,
    "DeepSeek": 100.0,
    "Anthropic": 0.0,
    "Google": 0.0,
    "Cohere": 0.0,
    "Fireworks": 0.0,
    "Cerebras": 0.0
  },
  "metadata": {
    "version": "3.0",
    "parallel_testing": false,
    "streaming_enabled": true,
    "timeout": 90,
    "retries": 3
  }
}